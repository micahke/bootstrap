{"docstore/data": {"633945d4-138a-4fe1-ba18-bf6198b981c7": {"__data__": {"id_": "633945d4-138a-4fe1-ba18-bf6198b981c7", "embedding": null, "metadata": {"file_name": "setup.py", "relative_path": "setup.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "8813e60e0d9f7cacf0c414ae4964816f", "node_type": "4", "metadata": {"file_name": "setup.py", "relative_path": "setup.py"}, "hash": "beeac4dbbf8b1d327c22c191d4f02661ee5291fa1a2ea10e001e5b4d17999daa"}}, "hash": "91f1d5478f7d90ebca40e5026e6a6b4d97045f86d49afd88fba26b0078aff179", "text": "from setuptools import setup, find_packages\n  \nsetup(\n    name='bootstrap',\n    version='0.1.0',\n    packages=find_packages(),\n    entry_points={\n        'console_scripts': [\n            'bootstrap = script.main:main',   \n        ],\n    },\n    install_requires=[\n        req.strip() for req in open('requirements.txt').readlines()\n    ],\n)", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "a33a62aa-a46a-434a-9916-2f4fadfe92a8": {"__data__": {"id_": "a33a62aa-a46a-434a-9916-2f4fadfe92a8", "embedding": null, "metadata": {"file_name": "llama_index.py", "relative_path": "llm/llama_index.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "471e918c4c6dd451b62cbafc115bdb9b", "node_type": "4", "metadata": {"file_name": "llama_index.py", "relative_path": "llm/llama_index.py"}, "hash": "7183910326257511d1a731d861a85cd950922069ba77059a53e87ac2a2d5e59a"}, "3": {"node_id": "96d1e53a-0d1e-4f63-bb66-45e6f393f6ff", "node_type": "1", "metadata": {"file_name": "llama_index.py", "relative_path": "llm/llama_index.py"}, "hash": "4fdd06502351e09a0d7a4d544ef7151f34ab4d50929776854259b2b223cdd128"}}, "hash": "bdf6ec546c722d66018a334321d9d17b27b842fb93c160b2b59cb0fd7daf689a", "text": "import hashlib\nfrom pydoc import text\nfrom typing import List\nfrom llama_index.indices.base import BaseIndex\nfrom llama_index.schema import BaseNode\nfrom llama_index.storage.docstore.simple_docstore import SimpleDocumentStore\nfrom llama_index.storage.index_store.simple_index_store import SimpleIndexStore\nfrom llama_index.vector_stores.simple import SimpleVectorStore\nimport openai\nimport os\nfrom data.errors import NO_API_KEY\nfrom llama_index import Document, ServiceContext, StorageContext, VectorStoreIndex, load_index_from_storage\nfrom util.fs import read_file\nfrom llama_index.node_parser import SimpleNodeParser\nfrom llama_index.llms import OpenAI\nfrom util.fs import get_bootstrap_dir\n\nclass LlamaClient:\n    def __init__(self) -> None:\n        api_key = os.getenv(\"OPENAI_API_KEY\")\n        if api_key is None:\n            print(NO_API_KEY)\n            exit(0)\n        else:\n            openai.api_key = api_key\n\n    def generate_doc(self, filepath: str) -> Document:\n        filename = filepath.split('/')[-1]\n        relative_path = os.path.relpath(filepath, os.getcwd())\n        doc =  Document(\n            text=read_file(filepath),\n            extra_info={\n                \"file_name\": filename,", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "96d1e53a-0d1e-4f63-bb66-45e6f393f6ff": {"__data__": {"id_": "96d1e53a-0d1e-4f63-bb66-45e6f393f6ff", "embedding": null, "metadata": {"file_name": "llama_index.py", "relative_path": "llm/llama_index.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "471e918c4c6dd451b62cbafc115bdb9b", "node_type": "4", "metadata": {"file_name": "llama_index.py", "relative_path": "llm/llama_index.py"}, "hash": "7183910326257511d1a731d861a85cd950922069ba77059a53e87ac2a2d5e59a"}, "2": {"node_id": "a33a62aa-a46a-434a-9916-2f4fadfe92a8", "node_type": "1", "metadata": {"file_name": "llama_index.py", "relative_path": "llm/llama_index.py"}, "hash": "bdf6ec546c722d66018a334321d9d17b27b842fb93c160b2b59cb0fd7daf689a"}, "3": {"node_id": "22011b34-a3a2-47ac-9b15-6c5b994fbc96", "node_type": "1", "metadata": {"file_name": "llama_index.py", "relative_path": "llm/llama_index.py"}, "hash": "29748a2bd149bbcb07d5fd6359d3d96612c0a53ea8971b9bf81564c20950aa33"}}, "hash": "4fdd06502351e09a0d7a4d544ef7151f34ab4d50929776854259b2b223cdd128", "text": "\"relative_path\": relative_path\n            }\n        )\n        # Set the ID as the MD5 hash of the filepath \n        hash = hashlib.md5(filepath.encode()).hexdigest()\n        doc.id_ = hash\n        return doc\n\n\n    def parse_nodes(self, docs: List[Document]) -> List[BaseNode]:\n        parser = SimpleNodeParser.from_defaults(\n            chunk_size=512,\n            chunk_overlap=20\n        )\n        nodes = parser.get_nodes_from_documents(docs)\n        return nodes\n\n    def generate_index_from_nodes(self, nodes: List[BaseNode]) -> VectorStoreIndex:\n        llm = OpenAI(model='gpt-4', temperature=0.1)\n        service_context = ServiceContext.from_defaults(\n            llm=llm\n        )\n        index = VectorStoreIndex(nodes, service_context=service_context)\n        return index", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "22011b34-a3a2-47ac-9b15-6c5b994fbc96": {"__data__": {"id_": "22011b34-a3a2-47ac-9b15-6c5b994fbc96", "embedding": null, "metadata": {"file_name": "llama_index.py", "relative_path": "llm/llama_index.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "471e918c4c6dd451b62cbafc115bdb9b", "node_type": "4", "metadata": {"file_name": "llama_index.py", "relative_path": "llm/llama_index.py"}, "hash": "7183910326257511d1a731d861a85cd950922069ba77059a53e87ac2a2d5e59a"}, "2": {"node_id": "96d1e53a-0d1e-4f63-bb66-45e6f393f6ff", "node_type": "1", "metadata": {"file_name": "llama_index.py", "relative_path": "llm/llama_index.py"}, "hash": "4fdd06502351e09a0d7a4d544ef7151f34ab4d50929776854259b2b223cdd128"}}, "hash": "29748a2bd149bbcb07d5fd6359d3d96612c0a53ea8971b9bf81564c20950aa33", "text": "def query(self, index: BaseIndex, prompt: str):\n        qe = index.as_query_engine(streaming=True)\n        response = qe.query(prompt)\n        print('\\n')\n        response.print_response_stream()\n\n    def save_index(self, index: BaseIndex):\n        storagepath = os.path.join(get_bootstrap_dir(), \"storage\")\n        index.storage_context.persist(storagepath)\n\n\n    def load_index(self) -> BaseIndex:\n        storagepath = os.path.join(get_bootstrap_dir(), \"storage\")\n        storage_context = StorageContext.from_defaults(\n            docstore=SimpleDocumentStore.from_persist_dir(persist_dir=storagepath),\n            vector_store=SimpleVectorStore.from_persist_dir(persist_dir=storagepath),\n            index_store=SimpleIndexStore.from_persist_dir(persist_dir=storagepath),\n        )\n        llm = OpenAI(model='gpt-4', temperature=0.1)\n        service_context = ServiceContext.from_defaults(\n            llm=llm\n        )\n        index = load_index_from_storage(storage_context)\n        index._service_context = service_context\n        return index", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "f0adbea2-cd6c-4094-baa7-e6b17e164024": {"__data__": {"id_": "f0adbea2-cd6c-4094-baa7-e6b17e164024", "embedding": null, "metadata": {"file_name": "walker.py", "relative_path": "util/walker.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "73dd1e6f7ba6481957549a310c957e4b", "node_type": "4", "metadata": {"file_name": "walker.py", "relative_path": "util/walker.py"}, "hash": "9faae27b17e12eb46640d03f85d8c414d4189c36a9f449de63827326e65003ad"}}, "hash": "aa4edeb52c41e6da8b270f8ad5c8aad2a4d475d3fa743cdcc7996a49e228a854", "text": "import os\nimport re\nfrom typing import List\nfrom data.config import Config\n\n\nclass FileWalker:\n    def __init__(self, config: Config, dir: str) -> None:\n        self.config = config\n        self.dir = dir\n        self.filepaths = []\n\n\n\n    def walk(self) -> List[str]:\n        filepaths = []\n        for dirpath, dirnames, filenames in os.walk(self.dir):\n            base_dirname = os.path.basename(dirpath)\n            if base_dirname in self.config.excluded_dirs:\n                dirnames[:] = []\n                continue\n            for filename in filenames:\n                if any(filename.endswith(ext) for ext in self.config.filetypes):\n                    filepaths.append(os.path.join(dirpath, filename))  \n        return filepaths", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "fccb5c06-9c28-4831-aec9-72e01bb50be2": {"__data__": {"id_": "fccb5c06-9c28-4831-aec9-72e01bb50be2", "embedding": null, "metadata": {"file_name": "parsers.py", "relative_path": "util/parsers.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "3146ead6697fe74d44d166aa2eed024a", "node_type": "4", "metadata": {"file_name": "parsers.py", "relative_path": "util/parsers.py"}, "hash": "6e951d8c885ea6625eda1032f5b6b1d5b7abfc8fe9615be6b76b709210ebbe54"}}, "hash": "b4be07547c57652a37911171476f2da9a98456f1c08e9e6175fd5fd7e0771d31", "text": "import yaml\nfrom data.config import Config\nfrom data.errors import NO_PROJECT_NAME\n\n\ndef parse_config_file(src: str) -> Config:\n    data = yaml.safe_load(src)\n    config = Config() \n    if \"project\" not in data:\n        print(NO_PROJECT_NAME)\n        return\n    \n    config.set_name(data[\"project\"])\n\n    if \"description\" in data:\n        config.set_description(data[\"description\"])\n\n    if \"filetypes\" in data:\n        config.set_filetypes(data['filetypes'])\n\n    if \"excluded_dirs\" in data:\n        config.set_excluded_dirs(data['excluded_dirs'])\n\n    return config", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "153d5c7e-5145-418f-8469-678b4d236024": {"__data__": {"id_": "153d5c7e-5145-418f-8469-678b4d236024", "embedding": null, "metadata": {"file_name": "fs.py", "relative_path": "util/fs.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "ff1d8cad4c58af36f3624910ac1be3e1", "node_type": "4", "metadata": {"file_name": "fs.py", "relative_path": "util/fs.py"}, "hash": "cef6d09f6e70cd6f92f479815b3d0ace99ce0f8dd0a50e5ae89989de1ab8e981"}, "3": {"node_id": "66e1a7a6-cd46-4b31-b27b-cadd01d2eebb", "node_type": "1", "metadata": {"file_name": "fs.py", "relative_path": "util/fs.py"}, "hash": "482970e1c16823a7bd2bde2e2c6c410b4760c1b2dc097574ded8bd6292b53f01"}}, "hash": "e727fec06dc9c5632f600b34c8b3eb73463f37e6b3afbd4004d68328d330b2d8", "text": "import os\nimport shutil\n\nBOOTSTRAP_FILE_NAME = \".bootstrap\"\n\ndef read_config() -> str:\n    rootdir = os.getcwd()\n    filepath = os.path.join(rootdir, BOOTSTRAP_FILE_NAME)\n    with open(filepath, 'r') as file:\n        return file.read()\n\ndef config_exists() -> bool:\n    rootdir = os.getcwd()\n    filepath = os.path.join(rootdir, BOOTSTRAP_FILE_NAME)\n    return os.path.exists(filepath)\n\ndef read_file(filepath: str) -> str:\n    with open(filepath, 'r') as file:\n        return file.read()\n\n\n\ndef bootstrap_dir_exists() -> bool:\n    rootdir = os.getcwd()\n    path = os.path.join(rootdir, \".boot\")\n    if os.path.exists(path):\n        return True\n    return False\n\ndef create_bootstrap_dir():\n    rootdir = os.getcwd()\n    path = os.path.join(rootdir, \".boot\")\n    os.mkdir(path)\n    os.mkdir(os.path.join(path, \"storage\"))\n\ndef get_bootstrap_dir():\n    rootdir = os.getcwd()\n    return os.path.join(rootdir, \".boot\")\n\n\ndef delete_bootstrap_dir():\n    dir = get_bootstrap_dir()\n    shutil.rmtree(dir)", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "66e1a7a6-cd46-4b31-b27b-cadd01d2eebb": {"__data__": {"id_": "66e1a7a6-cd46-4b31-b27b-cadd01d2eebb", "embedding": null, "metadata": {"file_name": "fs.py", "relative_path": "util/fs.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "ff1d8cad4c58af36f3624910ac1be3e1", "node_type": "4", "metadata": {"file_name": "fs.py", "relative_path": "util/fs.py"}, "hash": "cef6d09f6e70cd6f92f479815b3d0ace99ce0f8dd0a50e5ae89989de1ab8e981"}, "2": {"node_id": "153d5c7e-5145-418f-8469-678b4d236024", "node_type": "1", "metadata": {"file_name": "fs.py", "relative_path": "util/fs.py"}, "hash": "e727fec06dc9c5632f600b34c8b3eb73463f37e6b3afbd4004d68328d330b2d8"}}, "hash": "482970e1c16823a7bd2bde2e2c6c410b4760c1b2dc097574ded8bd6292b53f01", "text": "def get_snapshot_filepath() -> str:\n    return os.path.join(get_bootstrap_dir(), \"snapshot\")\n\ndef snapshot_exists() -> bool:\n    return os.path.exists(get_snapshot_filepath())", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "2a543b18-863b-4e75-a148-6a359516dbe1": {"__data__": {"id_": "2a543b18-863b-4e75-a148-6a359516dbe1", "embedding": null, "metadata": {"file_name": "md_output.py", "relative_path": "util/md_output.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "087008845694f9bddd6c94f117110834", "node_type": "4", "metadata": {"file_name": "md_output.py", "relative_path": "util/md_output.py"}, "hash": "c79583dbba119cb180331641c513bc7de31bc44995f97162730a146813cf79fc"}}, "hash": "d868bb968dcbb2102e2197c5ce8bb781f75794559e2e4e61f8f094f95046f3f0", "text": "# from rich import print\n# from rich.markdown import Markdown\n# from rich.syntax import Syntax\n#\n# markdown_text = \"\"\"\n# # Title\n# Here is some **bold text**, and some *italic text*.\n# \"\"\"\n# markdown = Markdown(markdown_text)\n# print(markdown)\n#\n# code_text = '''\n# def foo(bar):\n#     print(bar)\n# '''\n# syntax = Syntax(code_text, \"python\", theme=\"monokai\", line_numbers=True)\n# print(syntax)", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "66048890-36c9-4a2c-a304-a2f36ab38764": {"__data__": {"id_": "66048890-36c9-4a2c-a304-a2f36ab38764", "embedding": null, "metadata": {"file_name": "hash_test.py", "relative_path": "script/hash_test.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "dc7e8b0f6c24d21c7a6403f2759ca818", "node_type": "4", "metadata": {"file_name": "hash_test.py", "relative_path": "script/hash_test.py"}, "hash": "39ec429018cfc23ab4d37d80a703c0f648afd67f2272a2229cfa78adc324795a"}}, "hash": "2c6211a0fa55e6cf5c96936b5a17e59294e1194797dfa41f6af2b85a6db5f394", "text": "import hashlib\nimport os\n\ndef run():\n    dirname = os.path.dirname(__file__)\n    hash = hashlib.sha256()\n    with open(os.path.join(dirname, \"data/textfile.txt\"), 'rb') as file:\n        for block in iter(lambda: file.read(4096), b\"\"):\n            hash.update(block)\n    print(hash.hexdigest())\n\n\nif __name__ == \"__main__\":\n    run()", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "87bd40fa-f988-4bef-992a-9ba9e92e40ba": {"__data__": {"id_": "87bd40fa-f988-4bef-992a-9ba9e92e40ba", "embedding": null, "metadata": {"file_name": "main.py", "relative_path": "script/main.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "09fe6f109687e4e2026fd8cea14c68ce", "node_type": "4", "metadata": {"file_name": "main.py", "relative_path": "script/main.py"}, "hash": "7ef5f89691db513bc8eab0714cff3da225b54cf2ba9691361254ecf0cb925fbc"}, "3": {"node_id": "ded49ff3-9cbc-4a78-b0a6-1ff36140a887", "node_type": "1", "metadata": {"file_name": "main.py", "relative_path": "script/main.py"}, "hash": "9421f36f715cc193edd5e7051058b46c059307aede717665d559da6d0381c186"}}, "hash": "bb28c7af03b75878bf95efde90364dc3b0ecc277071f4dcf5dc9884325aa5205", "text": "import argparse\nfrom data.config import Config\nfrom data.snapshot import Snapshot\nfrom process.build import BuildProcess\nfrom process.delete import DeleteProcess\nfrom process.generation import GenerationProcess\nfrom process.keyprocess import KeyProcess\nfrom util.fs import config_exists, read_config, bootstrap_dir_exists, create_bootstrap_dir, delete_bootstrap_dir\nfrom data.errors import NO_CONFIG_FOUND, NO_QUERY_PROVIDED\nfrom util.parsers import parse_config_file\nfrom util.walker import FileWalker\nfrom llm.llama_index import LlamaClient\n\nparser = argparse.ArgumentParser(description=\"Enter your bootstrap command\")\nsubparsers = parser.add_subparsers(dest=\"command\")\n\nbuild_parser = subparsers.add_parser(\"build\")\ndelete_parser = subparsers.add_parser(\"delete\")\nask_parser = subparsers.add_parser(\"ask\")\nask_parser.add_argument('prompt', nargs=\"?\", default=\"\")\n\n# parser.add_argument(\"-b\", \"--build\", action=\"store_true\")\n# parser.add_argument(\"-d\",\"--delete\", action=\"store_true\")\n# parser.add_argument(\"-q\", \"--query\", nargs=\"?\", default=\"\")\n# parser.add_argument(\"--key\", type=str)\n\n\ndef main():\n    args = parser.parse_args()\n\n    if not config_exists():\n        print(NO_CONFIG_FOUND)\n        exit()\n    cfg_src = read_config()\n    config = parse_config_file(cfg_src)\n\n    # if args.key:\n    #     KeyProcess(args.key).run()\n\n    client = LlamaClient()\n\n    if not bootstrap_dir_exists():\n        create_bootstrap_dir()", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "ded49ff3-9cbc-4a78-b0a6-1ff36140a887": {"__data__": {"id_": "ded49ff3-9cbc-4a78-b0a6-1ff36140a887", "embedding": null, "metadata": {"file_name": "main.py", "relative_path": "script/main.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "09fe6f109687e4e2026fd8cea14c68ce", "node_type": "4", "metadata": {"file_name": "main.py", "relative_path": "script/main.py"}, "hash": "7ef5f89691db513bc8eab0714cff3da225b54cf2ba9691361254ecf0cb925fbc"}, "2": {"node_id": "87bd40fa-f988-4bef-992a-9ba9e92e40ba", "node_type": "1", "metadata": {"file_name": "main.py", "relative_path": "script/main.py"}, "hash": "bb28c7af03b75878bf95efde90364dc3b0ecc277071f4dcf5dc9884325aa5205"}}, "hash": "9421f36f715cc193edd5e7051058b46c059307aede717665d559da6d0381c186", "text": "if args.command == 'build':\n        BuildProcess(config, client).run()\n        exit(0)\n\n    if args.command == 'delete': \n        DeleteProcess().run()\n        exit(0)\n\n    if args.command == 'ask':\n        if args.prompt:\n            GenerationProcess(client, args.prompt).run()\n        else:\n            print(NO_QUERY_PROVIDED)\n\n\n\nif __name__ == \"__main__\":\n    main()", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "5cb53ee6-42d0-45a2-93ee-8d6e3d800e34": {"__data__": {"id_": "5cb53ee6-42d0-45a2-93ee-8d6e3d800e34", "embedding": null, "metadata": {"file_name": "config.py", "relative_path": "data/config.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "4c3ec91c7b3ea98fe88f3cd0cfa3f849", "node_type": "4", "metadata": {"file_name": "config.py", "relative_path": "data/config.py"}, "hash": "f815ae206c4108e443bd5192921592aec36b231aa8ba6bd00539333f8ed46f31"}}, "hash": "5cc45aae7d686e8a472606366a476a4c599c3c0c3408afc3ec425ca5f2cb78a3", "text": "from typing import Optional, List\n\nclass Config:\n    def __init__(self, name: Optional[str] = \"\") -> None:\n        self.name = name\n        self.description = \"\"\n        self.filetypes: List[str] = []\n        self.excluded_dirs: List[str] = []\n\n    def set_name(self, name: str):\n        self.name = name\n\n    def set_description(self, description: str):\n        self.description = description\n\n    def set_filetypes(self, filetypes: List[str]):\n        self.filetypes = filetypes\n\n    def set_excluded_dirs(self, excluded_dirs: List[str]):\n        self.excluded_dirs = excluded_dirs", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "b4dd3ed0-e984-4807-a4f4-08c0de2239fc": {"__data__": {"id_": "b4dd3ed0-e984-4807-a4f4-08c0de2239fc", "embedding": null, "metadata": {"file_name": "errors.py", "relative_path": "data/errors.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "cef4d7c2cadba464db48d1265b4a30c7", "node_type": "4", "metadata": {"file_name": "errors.py", "relative_path": "data/errors.py"}, "hash": "f73ec1aae475d03de1c083913800d92d047a29f8a9cededf034bc6ce0b1418ea"}}, "hash": "831ec779fc4bb8751b0d4dfaf265847c99191d05264df2b621b2eb6b5f23ec17", "text": "NO_CONFIG_FOUND = \"No config found. Please create a .bootstrap file and try again.\"\n\nNO_PROJECT_NAME = \"No project name has been set. Please set the `project` value in your bootstrap file\"\n\nNO_API_KEY = \"No OpenAI API key located. Please set `OPENAI_API_KEY in your path or run 'bootstrap --key YOUR_KEY' to do this for you.\"\n\nNO_QUERY_PROVIDED = \"There was no query provided, please try again.\"", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "a4279ccc-e92a-4912-b844-57809a918e7b": {"__data__": {"id_": "a4279ccc-e92a-4912-b844-57809a918e7b", "embedding": null, "metadata": {"file_name": "snapshot.py", "relative_path": "data/snapshot.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "e41e414f13327d3e8cc2eb129c09b9ce", "node_type": "4", "metadata": {"file_name": "snapshot.py", "relative_path": "data/snapshot.py"}, "hash": "349cb5471afdde978eda368c617283d4e07c58ba46f424f007feca2c3774af77"}, "3": {"node_id": "5b8314db-8f1d-49de-a44b-f54811a06f33", "node_type": "1", "metadata": {"file_name": "snapshot.py", "relative_path": "data/snapshot.py"}, "hash": "e91a4d460c7c6000a2809227f2ee60ce1213144b981b6f8e92b7d3eb716a996d"}}, "hash": "e56ed04a1fb3a55a28a5b4872211618b33766226ba4ec0aefe79bc5505850072", "text": "import hashlib\nfrom typing import List\nimport json\nfrom util.fs import get_snapshot_filepath\n\n\nclass Snapshot:\n    def __init__(self) -> None:\n        self.items = {}\n    \n    def add_item(self, filepath: str, hash: str):\n        self.items[filepath] = hash  \n\n    def save(self):\n        fp = get_snapshot_filepath()\n        with open(fp, \"w\") as file:\n            json.dump(self.items, file)\n\n    @classmethod\n    def load(cls):\n        fp = get_snapshot_filepath()\n        with open(fp, 'r') as file:\n            items = json.loads(file.read())\n        snapshot = Snapshot()\n        snapshot.items = items\n        return snapshot\n\n    @classmethod\n    def hash_file(cls, filepath: str) -> str:\n        hash = hashlib.sha256()\n        with open(filepath, \"rb\") as file:\n            for block in iter(lambda: file.read(4096), b\"\"):\n                hash.update(block)\n        return hash.hexdigest()\n\n    @classmethod\n    def build(cls, files: List[str]):\n        snapshot = Snapshot()\n        for filepath in files:\n            hash = cls.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "5b8314db-8f1d-49de-a44b-f54811a06f33": {"__data__": {"id_": "5b8314db-8f1d-49de-a44b-f54811a06f33", "embedding": null, "metadata": {"file_name": "snapshot.py", "relative_path": "data/snapshot.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "e41e414f13327d3e8cc2eb129c09b9ce", "node_type": "4", "metadata": {"file_name": "snapshot.py", "relative_path": "data/snapshot.py"}, "hash": "349cb5471afdde978eda368c617283d4e07c58ba46f424f007feca2c3774af77"}, "2": {"node_id": "a4279ccc-e92a-4912-b844-57809a918e7b", "node_type": "1", "metadata": {"file_name": "snapshot.py", "relative_path": "data/snapshot.py"}, "hash": "e56ed04a1fb3a55a28a5b4872211618b33766226ba4ec0aefe79bc5505850072"}}, "hash": "e91a4d460c7c6000a2809227f2ee60ce1213144b981b6f8e92b7d3eb716a996d", "text": "hash_file(filepath)\n            snapshot.add_item(filepath, hash)\n        return snapshot\n    \n\n    @classmethod\n    def compare(cls, old: 'Snapshot', new: 'Snapshot') -> tuple[List[str], List[str], List[str]]:\n        _new = []\n        _updated =  []\n        _deleted = []\n\n        # find new and updated files\n        for file_path, new_hash in new.items.items():\n            old_hash = old.items.get(file_path)\n            if old_hash is None:\n                _new.append(file_path)\n            elif old_hash != new_hash:\n                _updated.append(file_path)\n\n        # find deleted files\n        for file_path in old.items.keys():\n            if file_path not in new.items:\n                _deleted.append(file_path)\n\n        return _new, _updated, _deleted", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "57a64705-389e-4fda-b0f5-3f821b6e657b": {"__data__": {"id_": "57a64705-389e-4fda-b0f5-3f821b6e657b", "embedding": null, "metadata": {"file_name": "delete.py", "relative_path": "process/delete.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1e2d0c2555792e9e45661a316e9d688a", "node_type": "4", "metadata": {"file_name": "delete.py", "relative_path": "process/delete.py"}, "hash": "0c54c8b47d6e1a5fbaf807e7eb866e6659f1c474b9c59b4af4574dce116e3008"}}, "hash": "49e1f903f07c92073a25ffb467f72c5c71a15f77b058b1e0cc0fb01bf132d559", "text": "from typing import Any\nfrom process.process import Process\nfrom util.fs import delete_bootstrap_dir\n\n\nclass DeleteProcess(Process):\n    def __init__(self) -> None:\n        super().__init__()\n\n    def run(self, args: Any = None):\n        delete_bootstrap_dir()", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "311df7ea-1306-4a1c-8efd-a2142e34f60e": {"__data__": {"id_": "311df7ea-1306-4a1c-8efd-a2142e34f60e", "embedding": null, "metadata": {"file_name": "build.py", "relative_path": "process/build.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "02b2f09e831de8625a047296cc5efbe6", "node_type": "4", "metadata": {"file_name": "build.py", "relative_path": "process/build.py"}, "hash": "58ca5a7ed30133406fb092286b5fc33d0aa28fae654f2effde78d35569c3ee00"}, "3": {"node_id": "aac377af-cd27-4c7f-baea-491e619675d3", "node_type": "1", "metadata": {"file_name": "build.py", "relative_path": "process/build.py"}, "hash": "9c4c0cdc15aac2183b69c0a6b13f3710a93d2b811904db178d863c9d6d1e704f"}}, "hash": "494c13980a4437f277d8262443c9359f26f22b37db86991f9a5a67c0f35281b8", "text": "import hashlib\nfrom typing import Any, List\nfrom data.config import Config\nfrom data.snapshot import Snapshot\nfrom llm.llama_index import LlamaClient\nfrom process.process import Process\nfrom util.fs import snapshot_exists\nfrom util.walker import FileWalker\n\nclass BuildProcess(Process):\n    def __init__(self, config: Config, client: LlamaClient) -> None:\n        super().__init__()\n        self.config = config\n        self.client = client\n\n    def update_index(self, new: List[str], updated: List[str], deleted: List[str]):\n        index = self.client.load_index()\n        docs = []\n        for file in new:\n            doc = self.client.generate_doc(file)\n            docs.append(doc)\n\n        for file in updated:\n            hash = hashlib.md5(file.encode()).hexdigest()\n            try:\n                index.delete_ref_doc(hash)\n            except:\n                # One of the nodes already removed\n                pass\n\n            doc = self.client.generate_doc(file)\n            docs.append(doc)\n\n        nodes = self.client.parse_nodes(docs)\n        index.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "aac377af-cd27-4c7f-baea-491e619675d3": {"__data__": {"id_": "aac377af-cd27-4c7f-baea-491e619675d3", "embedding": null, "metadata": {"file_name": "build.py", "relative_path": "process/build.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "02b2f09e831de8625a047296cc5efbe6", "node_type": "4", "metadata": {"file_name": "build.py", "relative_path": "process/build.py"}, "hash": "58ca5a7ed30133406fb092286b5fc33d0aa28fae654f2effde78d35569c3ee00"}, "2": {"node_id": "311df7ea-1306-4a1c-8efd-a2142e34f60e", "node_type": "1", "metadata": {"file_name": "build.py", "relative_path": "process/build.py"}, "hash": "494c13980a4437f277d8262443c9359f26f22b37db86991f9a5a67c0f35281b8"}, "3": {"node_id": "f03153fa-41ee-4155-95ec-bcc2b798fd8a", "node_type": "1", "metadata": {"file_name": "build.py", "relative_path": "process/build.py"}, "hash": "1e23d415c78ebafb3ee3ae161ba4784b76ee8620e9c250037dc7d63a43f0b2cb"}}, "hash": "9c4c0cdc15aac2183b69c0a6b13f3710a93d2b811904db178d863c9d6d1e704f", "text": "client.parse_nodes(docs)\n        index.insert_nodes(nodes)\n        \n        for file in deleted:\n            hash = hashlib.md5(file.encode()).hexdigest()\n            try:\n                index.delete_ref_doc(hash)\n            except:\n                # One of the nodes already removed\n                pass\n        self.client.save_index(index)", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "f03153fa-41ee-4155-95ec-bcc2b798fd8a": {"__data__": {"id_": "f03153fa-41ee-4155-95ec-bcc2b798fd8a", "embedding": null, "metadata": {"file_name": "build.py", "relative_path": "process/build.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "02b2f09e831de8625a047296cc5efbe6", "node_type": "4", "metadata": {"file_name": "build.py", "relative_path": "process/build.py"}, "hash": "58ca5a7ed30133406fb092286b5fc33d0aa28fae654f2effde78d35569c3ee00"}, "2": {"node_id": "aac377af-cd27-4c7f-baea-491e619675d3", "node_type": "1", "metadata": {"file_name": "build.py", "relative_path": "process/build.py"}, "hash": "9c4c0cdc15aac2183b69c0a6b13f3710a93d2b811904db178d863c9d6d1e704f"}}, "hash": "1e23d415c78ebafb3ee3ae161ba4784b76ee8620e9c250037dc7d63a43f0b2cb", "text": "client.save_index(index)\n\n\n    def run(self, args: Any = None):\n        files = FileWalker(self.config, \".\").walk()\n        current_snapshot = Snapshot.build(files)\n        if snapshot_exists():\n            old_snapshot = Snapshot.load()\n            new, updated, deleted = Snapshot.compare(old_snapshot, current_snapshot)\n            self.update_index(new, updated, deleted)\n        else:\n            docs = []\n            for file in files:\n                doc = self.client.generate_doc(file)\n                docs.append(doc)\n\n            nodes = self.client.parse_nodes(docs)\n            index = self.client.generate_index_from_nodes(nodes)\n            self.client.save_index(index)\n        current_snapshot.save()", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "a5470978-ef62-4b4b-961b-b9f4aea81720": {"__data__": {"id_": "a5470978-ef62-4b4b-961b-b9f4aea81720", "embedding": null, "metadata": {"file_name": "generation.py", "relative_path": "process/generation.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "8880c0d89319431dae3c49d763b11383", "node_type": "4", "metadata": {"file_name": "generation.py", "relative_path": "process/generation.py"}, "hash": "c73f7fc019ed111f61ca870972baa84321831e62974e25b860e7597d77741698"}}, "hash": "82e385958ba5246479627c3d9b3161919f07ec05581c8844ab48f0b695dfc54b", "text": "from llm.llama_index import LlamaClient\nfrom process.process import Process\nfrom typing import Any\n\nclass GenerationProcess(Process):\n    def __init__(self, client: LlamaClient, prompt: str) -> None:\n        super().__init__()\n        self.client = client\n        self.prompt = prompt\n\n\n    def run(self, args: Any = None):\n        index = self.client.load_index()\n        self.client.query(index, self.prompt)", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "6d0bb17f-ce42-48ef-b4bb-174fff167af0": {"__data__": {"id_": "6d0bb17f-ce42-48ef-b4bb-174fff167af0", "embedding": null, "metadata": {"file_name": "keyprocess.py", "relative_path": "process/keyprocess.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "dde91e35690052e786795b16603467b8", "node_type": "4", "metadata": {"file_name": "keyprocess.py", "relative_path": "process/keyprocess.py"}, "hash": "7a2b14281b06df699065559b195c93aa167c00d532ab33bd50f1db6b65ffcb18"}}, "hash": "ff3d12ca22d829c115d82376b246b896d3fab068870083529ee320b7c66b125b", "text": "import os\nfrom typing import Any\nfrom process.process import Process\n\n\nclass KeyProcess(Process):\n    def __init__(self, key: str) -> None:\n        super().__init__()\n        self.key = key\n\n    def run(self, args: None):\n        os.environ['OPENAI_API_KEY'] = self.key", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "5b76242e-83ec-4ec8-9e60-5f913ff52a7c": {"__data__": {"id_": "5b76242e-83ec-4ec8-9e60-5f913ff52a7c", "embedding": null, "metadata": {"file_name": "process.py", "relative_path": "process/process.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b15009cde98d00318f0ac4aed9c62783", "node_type": "4", "metadata": {"file_name": "process.py", "relative_path": "process/process.py"}, "hash": "449261c61508bc476d010bc2c22a230303d8c25fde5e7d3267d11c70b2cd7386"}}, "hash": "1b4f9971ff38e3e05cbc03dcc68c56bf176a7fd65f96027668a02d76616c91eb", "text": "from abc import abstractmethod\nfrom typing import Any\n\nclass Process:\n    def __init__(self) -> None:\n        pass\n    \n    @abstractmethod\n    def run(self, args: Any):\n        pass", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "bdef5b8e-72ac-4657-a7f4-c895558f24fb": {"__data__": {"id_": "bdef5b8e-72ac-4657-a7f4-c895558f24fb", "embedding": null, "metadata": {"file_name": "llama_index.py", "relative_path": "llm/llama_index.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "471e918c4c6dd451b62cbafc115bdb9b", "node_type": "4", "metadata": {"file_name": "llama_index.py", "relative_path": "llm/llama_index.py"}, "hash": "2bf40d908a35216f80bf42f474e9b5635bf44cfbc6e8648f37d0d8c420041214"}, "3": {"node_id": "57b0ab6d-186c-4589-8fd7-832adfe993f8", "node_type": "1", "metadata": {"file_name": "llama_index.py", "relative_path": "llm/llama_index.py"}, "hash": "4fdd06502351e09a0d7a4d544ef7151f34ab4d50929776854259b2b223cdd128"}}, "hash": "bdf6ec546c722d66018a334321d9d17b27b842fb93c160b2b59cb0fd7daf689a", "text": "import hashlib\nfrom pydoc import text\nfrom typing import List\nfrom llama_index.indices.base import BaseIndex\nfrom llama_index.schema import BaseNode\nfrom llama_index.storage.docstore.simple_docstore import SimpleDocumentStore\nfrom llama_index.storage.index_store.simple_index_store import SimpleIndexStore\nfrom llama_index.vector_stores.simple import SimpleVectorStore\nimport openai\nimport os\nfrom data.errors import NO_API_KEY\nfrom llama_index import Document, ServiceContext, StorageContext, VectorStoreIndex, load_index_from_storage\nfrom util.fs import read_file\nfrom llama_index.node_parser import SimpleNodeParser\nfrom llama_index.llms import OpenAI\nfrom util.fs import get_bootstrap_dir\n\nclass LlamaClient:\n    def __init__(self) -> None:\n        api_key = os.getenv(\"OPENAI_API_KEY\")\n        if api_key is None:\n            print(NO_API_KEY)\n            exit(0)\n        else:\n            openai.api_key = api_key\n\n    def generate_doc(self, filepath: str) -> Document:\n        filename = filepath.split('/')[-1]\n        relative_path = os.path.relpath(filepath, os.getcwd())\n        doc =  Document(\n            text=read_file(filepath),\n            extra_info={\n                \"file_name\": filename,", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "57b0ab6d-186c-4589-8fd7-832adfe993f8": {"__data__": {"id_": "57b0ab6d-186c-4589-8fd7-832adfe993f8", "embedding": null, "metadata": {"file_name": "llama_index.py", "relative_path": "llm/llama_index.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "471e918c4c6dd451b62cbafc115bdb9b", "node_type": "4", "metadata": {"file_name": "llama_index.py", "relative_path": "llm/llama_index.py"}, "hash": "2bf40d908a35216f80bf42f474e9b5635bf44cfbc6e8648f37d0d8c420041214"}, "2": {"node_id": "bdef5b8e-72ac-4657-a7f4-c895558f24fb", "node_type": "1", "metadata": {"file_name": "llama_index.py", "relative_path": "llm/llama_index.py"}, "hash": "bdf6ec546c722d66018a334321d9d17b27b842fb93c160b2b59cb0fd7daf689a"}, "3": {"node_id": "7997fc47-e6df-4a7d-aa65-0040a1a48dfb", "node_type": "1", "metadata": {"file_name": "llama_index.py", "relative_path": "llm/llama_index.py"}, "hash": "944c9fb71f28f7042f798bb571fb71ded609370f35c1f26c536026e4f74d59c0"}}, "hash": "4fdd06502351e09a0d7a4d544ef7151f34ab4d50929776854259b2b223cdd128", "text": "\"relative_path\": relative_path\n            }\n        )\n        # Set the ID as the MD5 hash of the filepath \n        hash = hashlib.md5(filepath.encode()).hexdigest()\n        doc.id_ = hash\n        return doc\n\n\n    def parse_nodes(self, docs: List[Document]) -> List[BaseNode]:\n        parser = SimpleNodeParser.from_defaults(\n            chunk_size=512,\n            chunk_overlap=20\n        )\n        nodes = parser.get_nodes_from_documents(docs)\n        return nodes\n\n    def generate_index_from_nodes(self, nodes: List[BaseNode]) -> VectorStoreIndex:\n        llm = OpenAI(model='gpt-4', temperature=0.1)\n        service_context = ServiceContext.from_defaults(\n            llm=llm\n        )\n        index = VectorStoreIndex(nodes, service_context=service_context)\n        return index", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "7997fc47-e6df-4a7d-aa65-0040a1a48dfb": {"__data__": {"id_": "7997fc47-e6df-4a7d-aa65-0040a1a48dfb", "embedding": null, "metadata": {"file_name": "llama_index.py", "relative_path": "llm/llama_index.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "471e918c4c6dd451b62cbafc115bdb9b", "node_type": "4", "metadata": {"file_name": "llama_index.py", "relative_path": "llm/llama_index.py"}, "hash": "2bf40d908a35216f80bf42f474e9b5635bf44cfbc6e8648f37d0d8c420041214"}, "2": {"node_id": "57b0ab6d-186c-4589-8fd7-832adfe993f8", "node_type": "1", "metadata": {"file_name": "llama_index.py", "relative_path": "llm/llama_index.py"}, "hash": "4fdd06502351e09a0d7a4d544ef7151f34ab4d50929776854259b2b223cdd128"}, "3": {"node_id": "07119bb3-dbed-4cb6-b15c-3acdb7ee71de", "node_type": "1", "metadata": {"file_name": "llama_index.py", "relative_path": "llm/llama_index.py"}, "hash": "4fae0fec5f9eb6b0b284b12c422dde7d6b548957cb3de32d44c7fcfea442057e"}}, "hash": "944c9fb71f28f7042f798bb571fb71ded609370f35c1f26c536026e4f74d59c0", "text": "def query(self, index: BaseIndex, prompt: str):\n        qe = index.as_query_engine(streaming=True)\n        response = qe.query(prompt)\n\n        response_text = None\n        if response.response_txt is None and response.response_gen is not None:\n            response_txt = \"\"\n            for text in response.response_gen:\n                print(text, end=\"\", flush=True)\n                response_txt += text\n            print(response_txt)\n                \n            \n        print('\\n')\n        # response.print_response_stream()\n\n    def save_index(self, index: BaseIndex):\n        storagepath = os.path.join(get_bootstrap_dir(), \"storage\")\n        index.storage_context.persist(storagepath)", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "07119bb3-dbed-4cb6-b15c-3acdb7ee71de": {"__data__": {"id_": "07119bb3-dbed-4cb6-b15c-3acdb7ee71de", "embedding": null, "metadata": {"file_name": "llama_index.py", "relative_path": "llm/llama_index.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "471e918c4c6dd451b62cbafc115bdb9b", "node_type": "4", "metadata": {"file_name": "llama_index.py", "relative_path": "llm/llama_index.py"}, "hash": "2bf40d908a35216f80bf42f474e9b5635bf44cfbc6e8648f37d0d8c420041214"}, "2": {"node_id": "7997fc47-e6df-4a7d-aa65-0040a1a48dfb", "node_type": "1", "metadata": {"file_name": "llama_index.py", "relative_path": "llm/llama_index.py"}, "hash": "944c9fb71f28f7042f798bb571fb71ded609370f35c1f26c536026e4f74d59c0"}}, "hash": "4fae0fec5f9eb6b0b284b12c422dde7d6b548957cb3de32d44c7fcfea442057e", "text": "def load_index(self) -> BaseIndex:\n        storagepath = os.path.join(get_bootstrap_dir(), \"storage\")\n        storage_context = StorageContext.from_defaults(\n            docstore=SimpleDocumentStore.from_persist_dir(persist_dir=storagepath),\n            vector_store=SimpleVectorStore.from_persist_dir(persist_dir=storagepath),\n            index_store=SimpleIndexStore.from_persist_dir(persist_dir=storagepath),\n        )\n        llm = OpenAI(model='gpt-4', temperature=0.1)\n        service_context = ServiceContext.from_defaults(\n            llm=llm\n        )\n        index = load_index_from_storage(storage_context)\n        index._service_context = service_context\n        return index", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "782eceb8-6eac-49a0-a180-3797b9c31a9f": {"__data__": {"id_": "782eceb8-6eac-49a0-a180-3797b9c31a9f", "embedding": null, "metadata": {"file_name": "llama_index.py", "relative_path": "build/lib/llm/llama_index.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "8a52185c9f9a7ab0dce2a5e9fc84dccd", "node_type": "4", "metadata": {"file_name": "llama_index.py", "relative_path": "build/lib/llm/llama_index.py"}, "hash": "7c6c765c38d0b39231cfc1a99368110372510a49ec0e2adeff9a3dcf831e637e"}, "3": {"node_id": "6abfcf8e-2c1d-4be0-8218-ecc7908ffc05", "node_type": "1", "metadata": {"file_name": "llama_index.py", "relative_path": "build/lib/llm/llama_index.py"}, "hash": "230930439369d4ebd10cd7ec322d4bd14fd7c2fbfaa3cd1f88e8a3b9f9ae4384"}}, "hash": "46ec5dab0db0c943804b126a5ab606788fbe239b8218fce42dc1530a7ff33f03", "text": "import hashlib\nfrom pydoc import text\nfrom typing import List\nimport llama_index\nfrom llama_index.indices.base import BaseIndex\nfrom llama_index.schema import BaseNode\nfrom llama_index.storage.docstore.simple_docstore import SimpleDocumentStore\nfrom llama_index.storage.index_store.simple_index_store import SimpleIndexStore\nfrom llama_index.vector_stores.simple import SimpleVectorStore\nimport openai\nimport os\nfrom data.errors import NO_API_KEY\nfrom llama_index import Document, ServiceContext, StorageContext, VectorStoreIndex, load_index_from_storage\nfrom util.fs import read_file\nfrom llama_index.node_parser import SimpleNodeParser\nfrom llama_index.llms import OpenAI\nfrom util.fs import get_bootstrap_dir\n\nclass LlamaClient:\n    def __init__(self) -> None:\n        api_key = os.getenv(\"OPENAI_API_KEY\")\n        if api_key is None:\n            print(NO_API_KEY)\n            exit(0)\n        else:\n            openai.api_key = api_key\n\n    def generate_doc(self, filepath: str) -> Document:\n        filename = filepath.split('/')[-1]\n        relative_path = os.path.relpath(filepath, os.getcwd())\n        doc =  Document(\n            text=read_file(filepath),\n            extra_info={\n                \"file_name\": filename,", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "6abfcf8e-2c1d-4be0-8218-ecc7908ffc05": {"__data__": {"id_": "6abfcf8e-2c1d-4be0-8218-ecc7908ffc05", "embedding": null, "metadata": {"file_name": "llama_index.py", "relative_path": "build/lib/llm/llama_index.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "8a52185c9f9a7ab0dce2a5e9fc84dccd", "node_type": "4", "metadata": {"file_name": "llama_index.py", "relative_path": "build/lib/llm/llama_index.py"}, "hash": "7c6c765c38d0b39231cfc1a99368110372510a49ec0e2adeff9a3dcf831e637e"}, "2": {"node_id": "782eceb8-6eac-49a0-a180-3797b9c31a9f", "node_type": "1", "metadata": {"file_name": "llama_index.py", "relative_path": "build/lib/llm/llama_index.py"}, "hash": "46ec5dab0db0c943804b126a5ab606788fbe239b8218fce42dc1530a7ff33f03"}, "3": {"node_id": "ae9dc63e-af06-4d41-a92f-fc4999a9cf3a", "node_type": "1", "metadata": {"file_name": "llama_index.py", "relative_path": "build/lib/llm/llama_index.py"}, "hash": "c17073879593ca258fcf493d521fed158e9249ce489254d93c0da84e3a60a652"}}, "hash": "230930439369d4ebd10cd7ec322d4bd14fd7c2fbfaa3cd1f88e8a3b9f9ae4384", "text": "\"relative_path\": relative_path\n            }\n        )\n        # Set the ID as the MD5 hash of the filepath \n        hash = hashlib.md5(filepath.encode()).hexdigest()\n        doc.id_ = hash\n        return doc\n\n\n    def parse_nodes(self, docs: List[Document]) -> List[BaseNode]:\n        parser = SimpleNodeParser.from_defaults(\n            chunk_size=512,\n            chunk_overlap=20\n        )\n        nodes = parser.get_nodes_from_documents(docs)\n        return nodes\n\n    def generate_index_from_nodes(self, nodes: List[BaseNode]) -> VectorStoreIndex:\n        llm = OpenAI(model='gpt-4', temperature=0.1)\n        service_context = ServiceContext.from_defaults(\n            llm=llm\n        )\n        index = VectorStoreIndex(nodes, service_context=service_context)\n        return index", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "ae9dc63e-af06-4d41-a92f-fc4999a9cf3a": {"__data__": {"id_": "ae9dc63e-af06-4d41-a92f-fc4999a9cf3a", "embedding": null, "metadata": {"file_name": "llama_index.py", "relative_path": "build/lib/llm/llama_index.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "8a52185c9f9a7ab0dce2a5e9fc84dccd", "node_type": "4", "metadata": {"file_name": "llama_index.py", "relative_path": "build/lib/llm/llama_index.py"}, "hash": "7c6c765c38d0b39231cfc1a99368110372510a49ec0e2adeff9a3dcf831e637e"}, "2": {"node_id": "6abfcf8e-2c1d-4be0-8218-ecc7908ffc05", "node_type": "1", "metadata": {"file_name": "llama_index.py", "relative_path": "build/lib/llm/llama_index.py"}, "hash": "230930439369d4ebd10cd7ec322d4bd14fd7c2fbfaa3cd1f88e8a3b9f9ae4384"}, "3": {"node_id": "fe86b5e3-1fb6-4d58-a2b2-562be0d10e56", "node_type": "1", "metadata": {"file_name": "llama_index.py", "relative_path": "build/lib/llm/llama_index.py"}, "hash": "a821b285ce72c56b24ed6433de2e9bc653694ab352b27f99797df67e12a38243"}}, "hash": "c17073879593ca258fcf493d521fed158e9249ce489254d93c0da84e3a60a652", "text": "def query(self, index: BaseIndex, prompt: str):\n        qe = index.as_query_engine(streaming=True)\n        response = qe.query(prompt)\n\n        print('\\n')\n\n        response_text = None\n        if hasattr(response, 'response_gen') and response.response_gen is not None:\n            response_txt = \"\"\n            for text in response.response_gen:\n                print(text, end=\"\", flush=True)\n                response_txt += text\n        print(\"\\n\")\n            \n\n    def save_index(self, index: BaseIndex):\n        storagepath = os.path.join(get_bootstrap_dir(), \"storage\")\n        index.storage_context.persist(storagepath)", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "fe86b5e3-1fb6-4d58-a2b2-562be0d10e56": {"__data__": {"id_": "fe86b5e3-1fb6-4d58-a2b2-562be0d10e56", "embedding": null, "metadata": {"file_name": "llama_index.py", "relative_path": "build/lib/llm/llama_index.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "8a52185c9f9a7ab0dce2a5e9fc84dccd", "node_type": "4", "metadata": {"file_name": "llama_index.py", "relative_path": "build/lib/llm/llama_index.py"}, "hash": "7c6c765c38d0b39231cfc1a99368110372510a49ec0e2adeff9a3dcf831e637e"}, "2": {"node_id": "ae9dc63e-af06-4d41-a92f-fc4999a9cf3a", "node_type": "1", "metadata": {"file_name": "llama_index.py", "relative_path": "build/lib/llm/llama_index.py"}, "hash": "c17073879593ca258fcf493d521fed158e9249ce489254d93c0da84e3a60a652"}}, "hash": "a821b285ce72c56b24ed6433de2e9bc653694ab352b27f99797df67e12a38243", "text": "def load_index(self) -> BaseIndex:\n        storagepath = os.path.join(get_bootstrap_dir(), \"storage\")\n        storage_context = StorageContext.from_defaults(\n            docstore=SimpleDocumentStore.from_persist_dir(persist_dir=storagepath),\n            vector_store=SimpleVectorStore.from_persist_dir(persist_dir=storagepath),\n            index_store=SimpleIndexStore.from_persist_dir(persist_dir=storagepath),\n        )\n        llm = OpenAI(model='gpt-4', temperature=0.1)\n        service_context = ServiceContext.from_defaults(\n            llm=llm\n        )\n        index = load_index_from_storage(storage_context)\n        index._service_context = service_context\n        return index", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "ce16c0f7-71fd-461a-8c38-b24ad0ac7952": {"__data__": {"id_": "ce16c0f7-71fd-461a-8c38-b24ad0ac7952", "embedding": null, "metadata": {"file_name": "walker.py", "relative_path": "build/lib/util/walker.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "ed859f1af1f723ade33122ad20d19010", "node_type": "4", "metadata": {"file_name": "walker.py", "relative_path": "build/lib/util/walker.py"}, "hash": "96bbfb46a9491ef1e08115c660d35351a82a7f88a01d376fdc54eb89c9a601f3"}}, "hash": "fc1336f9b66c7c04c029b24755e014cdf4783bfc2bf209143ff81b7da14b3007", "text": "import os\nimport re\nfrom typing import List\nfrom data.config import Config\n\n\nclass FileWalker:\n    def __init__(self, config: Config, dir: str) -> None:\n        self.config = config\n        self.dir = dir\n        self.filepaths = []\n\n\n\n    def walk(self) -> List[str]:\n        filepaths = []\n        for dirpath, dirnames, filenames in os.walk(self.dir):\n            base_dirname = os.path.basename(dirpath)\n            if base_dirname in self.config.excluded_dirs:\n                dirnames[:] = []\n                continue\n            for filename in filenames:\n                if any(filename.endswith(ext) for ext in self.config.filetypes):\n                    filepaths.append(os.path.join(dirpath, filename))  \n        return filepaths", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "1472d2e0-17d5-40c0-b385-e39db42b2a90": {"__data__": {"id_": "1472d2e0-17d5-40c0-b385-e39db42b2a90", "embedding": null, "metadata": {"file_name": "parsers.py", "relative_path": "build/lib/util/parsers.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "a0462033740a6cd37a9588291ad89fdd", "node_type": "4", "metadata": {"file_name": "parsers.py", "relative_path": "build/lib/util/parsers.py"}, "hash": "894fcd813c55546149332d6095e3d4305a72befc1aae82e69263e6084138310a"}}, "hash": "70eaa01bdeef031b94fb39b5b436b91883f370f4b4fdf4c0748012a3cc02b4ad", "text": "import yaml\nfrom data.config import Config\nfrom data.errors import NO_PROJECT_NAME\n\n\ndef parse_config_file(src: str) -> Config:\n    data = yaml.safe_load(src)\n    config = Config() \n    if \"project\" not in data:\n        print(NO_PROJECT_NAME)\n        return\n    \n    config.set_name(data[\"project\"])\n\n    if \"description\" in data:\n        config.set_description(data[\"description\"])\n\n    if \"filetypes\" in data:\n        config.set_filetypes(data['filetypes'])\n\n    if \"excluded_dirs\" in data:\n        config.set_excluded_dirs(data['excluded_dirs'])\n\n    return config", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "0ea1aa63-b1a3-474b-aedf-643c9501e26b": {"__data__": {"id_": "0ea1aa63-b1a3-474b-aedf-643c9501e26b", "embedding": null, "metadata": {"file_name": "fs.py", "relative_path": "build/lib/util/fs.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "af98f0e16176160af49213efb7201ef5", "node_type": "4", "metadata": {"file_name": "fs.py", "relative_path": "build/lib/util/fs.py"}, "hash": "cb21b620af1867c12295f18eec7ed13e4bd293a84031fb032eb411b93cd89268"}, "3": {"node_id": "fb5765fe-a265-4242-886a-8b3da8f73dbc", "node_type": "1", "metadata": {"file_name": "fs.py", "relative_path": "build/lib/util/fs.py"}, "hash": "be041b68179bee19678aba0ff7a9d641adcc3970ceb5b81ae482c6138706b135"}}, "hash": "098de338b16b0a60cd70d1f81e22076ae1199a789954dd75f6eaad96ab40029d", "text": "import os\nimport shutil\n\nBOOTSTRAP_FILE_NAME = \".bootstrap\"\n\ndef read_config() -> str:\n    rootdir = os.getcwd()\n    filepath = os.path.join(rootdir, BOOTSTRAP_FILE_NAME)\n    with open(filepath, 'r') as file:\n        return file.read()\n\ndef config_exists() -> bool:\n    rootdir = os.getcwd()\n    filepath = os.path.join(rootdir, BOOTSTRAP_FILE_NAME)\n    return os.path.exists(filepath)\n\ndef read_file(filepath: str) -> str:\n    with open(filepath, 'r') as file:\n        return file.read()\n\n\n\ndef bootstrap_dir_exists() -> bool:\n    rootdir = os.getcwd()\n    path = os.path.join(rootdir, \".boot\")\n    if os.path.exists(path):\n        return True\n    return False\n\ndef create_bootstrap_dir():\n    rootdir = os.getcwd()\n    path = os.path.join(rootdir, \".boot\")\n    os.mkdir(path)\n    os.mkdir(os.path.join(path, \"storage\"))\n\ndef get_bootstrap_dir():\n    rootdir = os.getcwd()\n    return os.path.join(rootdir, \".boot\")\n\n\ndef delete_bootstrap_dir():\n    dir = get_bootstrap_dir()\n    shutil.rmtree(dir)", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "fb5765fe-a265-4242-886a-8b3da8f73dbc": {"__data__": {"id_": "fb5765fe-a265-4242-886a-8b3da8f73dbc", "embedding": null, "metadata": {"file_name": "fs.py", "relative_path": "build/lib/util/fs.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "af98f0e16176160af49213efb7201ef5", "node_type": "4", "metadata": {"file_name": "fs.py", "relative_path": "build/lib/util/fs.py"}, "hash": "cb21b620af1867c12295f18eec7ed13e4bd293a84031fb032eb411b93cd89268"}, "2": {"node_id": "0ea1aa63-b1a3-474b-aedf-643c9501e26b", "node_type": "1", "metadata": {"file_name": "fs.py", "relative_path": "build/lib/util/fs.py"}, "hash": "098de338b16b0a60cd70d1f81e22076ae1199a789954dd75f6eaad96ab40029d"}}, "hash": "be041b68179bee19678aba0ff7a9d641adcc3970ceb5b81ae482c6138706b135", "text": "def get_snapshot_filepath() -> str:\n    return os.path.join(get_bootstrap_dir(), \"snapshot\")\n\ndef snapshot_exists() -> bool:\n    return os.path.exists(get_snapshot_filepath())", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "62c517be-3c60-4769-a9e9-9cda726c5551": {"__data__": {"id_": "62c517be-3c60-4769-a9e9-9cda726c5551", "embedding": null, "metadata": {"file_name": "md_output.py", "relative_path": "build/lib/util/md_output.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "2639def6322916535b7c11b75b12ee16", "node_type": "4", "metadata": {"file_name": "md_output.py", "relative_path": "build/lib/util/md_output.py"}, "hash": "d25f0cae9b11f03de1cb7ea5e6547aa92da76bfd36c7b4b169c87a6859568359"}}, "hash": "9b17e55b5f5e4fa9a057384fdb7ea0db8d3d5b761e521ed07b95e4c5f8b785c8", "text": "# from rich import print\n# from rich.markdown import Markdown\n# from rich.syntax import Syntax\n#\n# markdown_text = \"\"\"\n# # Title\n# Here is some **bold text**, and some *italic text*.\n# \"\"\"\n# markdown = Markdown(markdown_text)\n# print(markdown)\n#\n# code_text = '''\n# def foo(bar):\n#     print(bar)\n# '''\n# syntax = Syntax(code_text, \"python\", theme=\"monokai\", line_numbers=True)\n# print(syntax)", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "f5da64c4-bec1-49e2-9e24-b43edcd53873": {"__data__": {"id_": "f5da64c4-bec1-49e2-9e24-b43edcd53873", "embedding": null, "metadata": {"file_name": "hash_test.py", "relative_path": "build/lib/script/hash_test.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "4e3fb7d231772335068371bbf17ca1f3", "node_type": "4", "metadata": {"file_name": "hash_test.py", "relative_path": "build/lib/script/hash_test.py"}, "hash": "9b094666f0f069662ffe229888a09612c957657c77d8b0369b685099cb92a628"}}, "hash": "abf6e2b4547e9312737a5744190ce81078f5cfe6675837732b95585818b9b623", "text": "import hashlib\nimport os\n\ndef run():\n    dirname = os.path.dirname(__file__)\n    hash = hashlib.sha256()\n    with open(os.path.join(dirname, \"data/textfile.txt\"), 'rb') as file:\n        for block in iter(lambda: file.read(4096), b\"\"):\n            hash.update(block)\n    print(hash.hexdigest())\n\n\nif __name__ == \"__main__\":\n    run()", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "853bdd10-d43e-4221-ac7f-4f9533d8a078": {"__data__": {"id_": "853bdd10-d43e-4221-ac7f-4f9533d8a078", "embedding": null, "metadata": {"file_name": "main.py", "relative_path": "build/lib/script/main.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "24a25fe904c858c2b257d2e6d8165f9b", "node_type": "4", "metadata": {"file_name": "main.py", "relative_path": "build/lib/script/main.py"}, "hash": "c56ccdfcf92a4fc83403c680f95cd5f52b0081160df9637902bcfbac8fbb7742"}, "3": {"node_id": "a8f0273f-41e3-43cf-b046-eee446deba9b", "node_type": "1", "metadata": {"file_name": "main.py", "relative_path": "build/lib/script/main.py"}, "hash": "e77d87e78d20e78ffef3f18079705a04c724b78117b2f995206f7ba110ee3816"}}, "hash": "afdc59d234d61eb23e0b6bd5250bfe6125ef1034a96a3024402ec17797e6d884", "text": "import argparse\nfrom data.config import Config\nfrom data.snapshot import Snapshot\nfrom process.build import BuildProcess\nfrom process.delete import DeleteProcess\nfrom process.generation import GenerationProcess\nfrom process.keyprocess import KeyProcess\nfrom util.fs import config_exists, read_config, bootstrap_dir_exists, create_bootstrap_dir, delete_bootstrap_dir\nfrom data.errors import NO_CONFIG_FOUND, NO_QUERY_PROVIDED\nfrom util.parsers import parse_config_file\nfrom util.walker import FileWalker\nfrom llm.llama_index import LlamaClient\n\nparser = argparse.ArgumentParser(description=\"Enter your bootstrap command\")\nsubparsers = parser.add_subparsers(dest=\"command\")\n\nbuild_parser = subparsers.add_parser(\"build\")\ndelete_parser = subparsers.add_parser(\"delete\")\nask_parser = subparsers.add_parser(\"ask\")\nask_parser.add_argument('prompt', nargs=\"?\", default=\"\")\n\n# parser.add_argument(\"-b\", \"--build\", action=\"store_true\")\n# parser.add_argument(\"-d\",\"--delete\", action=\"store_true\")\n# parser.add_argument(\"-q\", \"--query\", nargs=\"?\", default=\"\")\n# parser.add_argument(\"--key\", type=str)\n\n\ndef main():\n    args = parser.parse_args()\n\n    if not config_exists():\n        print(NO_CONFIG_FOUND)\n        exit()\n    cfg_src = read_config()\n    config = parse_config_file(cfg_src)\n\n    # if args.key:\n    #     KeyProcess(args.key).run()\n\n    client = LlamaClient()\n\n    if not bootstrap_dir_exists():\n        create_bootstrap_dir()", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "a8f0273f-41e3-43cf-b046-eee446deba9b": {"__data__": {"id_": "a8f0273f-41e3-43cf-b046-eee446deba9b", "embedding": null, "metadata": {"file_name": "main.py", "relative_path": "build/lib/script/main.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "24a25fe904c858c2b257d2e6d8165f9b", "node_type": "4", "metadata": {"file_name": "main.py", "relative_path": "build/lib/script/main.py"}, "hash": "c56ccdfcf92a4fc83403c680f95cd5f52b0081160df9637902bcfbac8fbb7742"}, "2": {"node_id": "853bdd10-d43e-4221-ac7f-4f9533d8a078", "node_type": "1", "metadata": {"file_name": "main.py", "relative_path": "build/lib/script/main.py"}, "hash": "afdc59d234d61eb23e0b6bd5250bfe6125ef1034a96a3024402ec17797e6d884"}}, "hash": "e77d87e78d20e78ffef3f18079705a04c724b78117b2f995206f7ba110ee3816", "text": "if args.command == 'build':\n        BuildProcess(config, client).run()\n        exit(0)\n\n    if args.command == 'delete': \n        DeleteProcess().run()\n        exit(0)\n\n    if args.command == 'ask':\n        if args.prompt:\n            GenerationProcess(client, args.prompt).run()\n        else:\n            print(NO_QUERY_PROVIDED)\n\n\n\nif __name__ == \"__main__\":\n    main()", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "2286ddd8-3e4b-4082-9888-fe97903f2b0c": {"__data__": {"id_": "2286ddd8-3e4b-4082-9888-fe97903f2b0c", "embedding": null, "metadata": {"file_name": "config.py", "relative_path": "build/lib/data/config.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "330fadb6c2d895324f6ff90fd6e346c7", "node_type": "4", "metadata": {"file_name": "config.py", "relative_path": "build/lib/data/config.py"}, "hash": "aed6a87e5b844570b4f3ee2992fcd03b89a368859b873d0b95c3b93414ab2469"}}, "hash": "29231319bb01af0335e4316a16a78917895a43c373eb7c55b9f73d44a6cd4b67", "text": "from typing import Optional, List\n\nclass Config:\n    def __init__(self, name: Optional[str] = \"\") -> None:\n        self.name = name\n        self.description = \"\"\n        self.filetypes: List[str] = []\n        self.excluded_dirs: List[str] = []\n\n    def set_name(self, name: str):\n        self.name = name\n\n    def set_description(self, description: str):\n        self.description = description\n\n    def set_filetypes(self, filetypes: List[str]):\n        self.filetypes = filetypes\n\n    def set_excluded_dirs(self, excluded_dirs: List[str]):\n        self.excluded_dirs = excluded_dirs", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "61931ba0-ac02-40f2-9770-248a7c6420c1": {"__data__": {"id_": "61931ba0-ac02-40f2-9770-248a7c6420c1", "embedding": null, "metadata": {"file_name": "errors.py", "relative_path": "build/lib/data/errors.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d11d604739e0ae4e9975fd32ac402e84", "node_type": "4", "metadata": {"file_name": "errors.py", "relative_path": "build/lib/data/errors.py"}, "hash": "687f7e860eaf9b43e51e6bf2d61627082457640f1b3488536af3c5e928e300c6"}}, "hash": "7ef10f02f0ef4d3ae00e9af03c04e556f132b83a0567795de1fcd252ffc604a3", "text": "NO_CONFIG_FOUND = \"No config found. Please create a .bootstrap file and try again.\"\n\nNO_PROJECT_NAME = \"No project name has been set. Please set the `project` value in your bootstrap file\"\n\nNO_API_KEY = \"No OpenAI API key located. Please set `OPENAI_API_KEY in your path or run 'bootstrap --key YOUR_KEY' to do this for you.\"\n\nNO_QUERY_PROVIDED = \"There was no query provided, please try again.\"", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "bd4810dc-4009-4a1b-be84-cea1b18077f4": {"__data__": {"id_": "bd4810dc-4009-4a1b-be84-cea1b18077f4", "embedding": null, "metadata": {"file_name": "snapshot.py", "relative_path": "build/lib/data/snapshot.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "2db495b92e26bf76ddbc90c959af81b1", "node_type": "4", "metadata": {"file_name": "snapshot.py", "relative_path": "build/lib/data/snapshot.py"}, "hash": "f76d57d65af56b188d85160c87ed2b4fee199a8234602bc64bcd55e57d239e9f"}, "3": {"node_id": "7e309e8b-08b0-4db4-af2d-d0c389ddd7f8", "node_type": "1", "metadata": {"file_name": "snapshot.py", "relative_path": "build/lib/data/snapshot.py"}, "hash": "3e9723625316d68b926d711118e923a4076c62296267807962c6f2138a9d6fc5"}}, "hash": "544dad8dc27837f5af6e3afa4d5a37b3b0f37631686edce6df5d324119ed24e5", "text": "import hashlib\nfrom typing import List\nimport json\nfrom util.fs import get_snapshot_filepath\n\n\nclass Snapshot:\n    def __init__(self) -> None:\n        self.items = {}\n    \n    def add_item(self, filepath: str, hash: str):\n        self.items[filepath] = hash  \n\n    def save(self):\n        fp = get_snapshot_filepath()\n        with open(fp, \"w\") as file:\n            json.dump(self.items, file)\n\n    @classmethod\n    def load(cls):\n        fp = get_snapshot_filepath()\n        with open(fp, 'r') as file:\n            items = json.loads(file.read())\n        snapshot = Snapshot()\n        snapshot.items = items\n        return snapshot\n\n    @classmethod\n    def hash_file(cls, filepath: str) -> str:\n        hash = hashlib.sha256()\n        with open(filepath, \"rb\") as file:\n            for block in iter(lambda: file.read(4096), b\"\"):\n                hash.update(block)\n        return hash.hexdigest()\n\n    @classmethod\n    def build(cls, files: List[str]):\n        snapshot = Snapshot()\n        for filepath in files:\n            hash = cls.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "7e309e8b-08b0-4db4-af2d-d0c389ddd7f8": {"__data__": {"id_": "7e309e8b-08b0-4db4-af2d-d0c389ddd7f8", "embedding": null, "metadata": {"file_name": "snapshot.py", "relative_path": "build/lib/data/snapshot.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "2db495b92e26bf76ddbc90c959af81b1", "node_type": "4", "metadata": {"file_name": "snapshot.py", "relative_path": "build/lib/data/snapshot.py"}, "hash": "f76d57d65af56b188d85160c87ed2b4fee199a8234602bc64bcd55e57d239e9f"}, "2": {"node_id": "bd4810dc-4009-4a1b-be84-cea1b18077f4", "node_type": "1", "metadata": {"file_name": "snapshot.py", "relative_path": "build/lib/data/snapshot.py"}, "hash": "544dad8dc27837f5af6e3afa4d5a37b3b0f37631686edce6df5d324119ed24e5"}}, "hash": "3e9723625316d68b926d711118e923a4076c62296267807962c6f2138a9d6fc5", "text": "hash_file(filepath)\n            snapshot.add_item(filepath, hash)\n        return snapshot\n    \n\n    @classmethod\n    def compare(cls, old: 'Snapshot', new: 'Snapshot') -> tuple[List[str], List[str], List[str]]:\n        _new = []\n        _updated =  []\n        _deleted = []\n\n        # find new and updated files\n        for file_path, new_hash in new.items.items():\n            old_hash = old.items.get(file_path)\n            if old_hash is None:\n                _new.append(file_path)\n            elif old_hash != new_hash:\n                _updated.append(file_path)\n\n        # find deleted files\n        for file_path in old.items.keys():\n            if file_path not in new.items:\n                _deleted.append(file_path)\n\n        return _new, _updated, _deleted", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "a63fa65b-881d-4380-8c88-929d555df0a0": {"__data__": {"id_": "a63fa65b-881d-4380-8c88-929d555df0a0", "embedding": null, "metadata": {"file_name": "delete.py", "relative_path": "build/lib/process/delete.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "090248470d4ea28d7f2d4b5208597712", "node_type": "4", "metadata": {"file_name": "delete.py", "relative_path": "build/lib/process/delete.py"}, "hash": "544c8f3b948d2bf5ddd18f57ddd227acfe4576eebf21f452fb374e5d4ffae62d"}}, "hash": "246792c7870b5f18d3e4db67c2a6c57e84d388222d2fae3ed5af04161ce695c4", "text": "from typing import Any\nfrom process.process import Process\nfrom util.fs import delete_bootstrap_dir\n\n\nclass DeleteProcess(Process):\n    def __init__(self) -> None:\n        super().__init__()\n\n    def run(self, args: Any = None):\n        delete_bootstrap_dir()", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "6355f745-a496-4d28-abef-d65d79c9312c": {"__data__": {"id_": "6355f745-a496-4d28-abef-d65d79c9312c", "embedding": null, "metadata": {"file_name": "build.py", "relative_path": "build/lib/process/build.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "6fa6f13a00c78b8a406d654d7593b6b7", "node_type": "4", "metadata": {"file_name": "build.py", "relative_path": "build/lib/process/build.py"}, "hash": "35c32dfb06d7916b192c9cdcbea2a0b20166225ae376b62bbe5b5a410fe1aaf6"}, "3": {"node_id": "d89469d2-4107-4759-abab-45c89e20043a", "node_type": "1", "metadata": {"file_name": "build.py", "relative_path": "build/lib/process/build.py"}, "hash": "cca461f991d35072ef667d7d9131637f55e51b800f78029d4ea93b640aefba66"}}, "hash": "73a2865f5be6186e985d303e7fd8e9d0fa9792399366339131d6a97d0e7be4e0", "text": "import hashlib\nfrom typing import Any, List\nfrom data.config import Config\nfrom data.snapshot import Snapshot\nfrom llm.llama_index import LlamaClient\nfrom process.process import Process\nfrom util.fs import snapshot_exists\nfrom util.walker import FileWalker\n\nclass BuildProcess(Process):\n    def __init__(self, config: Config, client: LlamaClient) -> None:\n        super().__init__()\n        self.config = config\n        self.client = client\n\n    def update_index(self, new: List[str], updated: List[str], deleted: List[str]):\n        index = self.client.load_index()\n        docs = []\n        for file in new:\n            doc = self.client.generate_doc(file)\n            docs.append(doc)\n\n        for file in updated:\n            hash = hashlib.md5(file.encode()).hexdigest()\n            try:\n                index.delete_ref_doc(hash)\n            except:\n                # One of the nodes already removed\n                pass\n\n            doc = self.client.generate_doc(file)\n            docs.append(doc)\n\n        nodes = self.client.parse_nodes(docs)\n        index.", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "d89469d2-4107-4759-abab-45c89e20043a": {"__data__": {"id_": "d89469d2-4107-4759-abab-45c89e20043a", "embedding": null, "metadata": {"file_name": "build.py", "relative_path": "build/lib/process/build.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "6fa6f13a00c78b8a406d654d7593b6b7", "node_type": "4", "metadata": {"file_name": "build.py", "relative_path": "build/lib/process/build.py"}, "hash": "35c32dfb06d7916b192c9cdcbea2a0b20166225ae376b62bbe5b5a410fe1aaf6"}, "2": {"node_id": "6355f745-a496-4d28-abef-d65d79c9312c", "node_type": "1", "metadata": {"file_name": "build.py", "relative_path": "build/lib/process/build.py"}, "hash": "73a2865f5be6186e985d303e7fd8e9d0fa9792399366339131d6a97d0e7be4e0"}, "3": {"node_id": "60fbbd02-e267-4b78-bb85-520a9718fd3f", "node_type": "1", "metadata": {"file_name": "build.py", "relative_path": "build/lib/process/build.py"}, "hash": "4d6767c133025bc6e32905f019842f993828e5531ce5571670ead457d11b9baf"}}, "hash": "cca461f991d35072ef667d7d9131637f55e51b800f78029d4ea93b640aefba66", "text": "client.parse_nodes(docs)\n        index.insert_nodes(nodes)\n        \n        for file in deleted:\n            hash = hashlib.md5(file.encode()).hexdigest()\n            try:\n                index.delete_ref_doc(hash)\n            except:\n                # One of the nodes already removed\n                pass\n        self.client.save_index(index)", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "60fbbd02-e267-4b78-bb85-520a9718fd3f": {"__data__": {"id_": "60fbbd02-e267-4b78-bb85-520a9718fd3f", "embedding": null, "metadata": {"file_name": "build.py", "relative_path": "build/lib/process/build.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "6fa6f13a00c78b8a406d654d7593b6b7", "node_type": "4", "metadata": {"file_name": "build.py", "relative_path": "build/lib/process/build.py"}, "hash": "35c32dfb06d7916b192c9cdcbea2a0b20166225ae376b62bbe5b5a410fe1aaf6"}, "2": {"node_id": "d89469d2-4107-4759-abab-45c89e20043a", "node_type": "1", "metadata": {"file_name": "build.py", "relative_path": "build/lib/process/build.py"}, "hash": "cca461f991d35072ef667d7d9131637f55e51b800f78029d4ea93b640aefba66"}}, "hash": "4d6767c133025bc6e32905f019842f993828e5531ce5571670ead457d11b9baf", "text": "client.save_index(index)\n\n\n    def run(self, args: Any = None):\n        files = FileWalker(self.config, \".\").walk()\n        current_snapshot = Snapshot.build(files)\n        if snapshot_exists():\n            old_snapshot = Snapshot.load()\n            new, updated, deleted = Snapshot.compare(old_snapshot, current_snapshot)\n            self.update_index(new, updated, deleted)\n        else:\n            docs = []\n            for file in files:\n                doc = self.client.generate_doc(file)\n                docs.append(doc)\n\n            nodes = self.client.parse_nodes(docs)\n            index = self.client.generate_index_from_nodes(nodes)\n            self.client.save_index(index)\n        current_snapshot.save()", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "c9650001-3a2a-4a0e-8a25-d8ca721f2192": {"__data__": {"id_": "c9650001-3a2a-4a0e-8a25-d8ca721f2192", "embedding": null, "metadata": {"file_name": "generation.py", "relative_path": "build/lib/process/generation.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "21e2f269418ce99fb490453c45e8727a", "node_type": "4", "metadata": {"file_name": "generation.py", "relative_path": "build/lib/process/generation.py"}, "hash": "e4f2aaae02b708c4e60174079e9074a51b21a48383442bb0d5138fdd59f94815"}}, "hash": "afdc9b4c2e353056f406658b410562e8a9875f57c8703cab2a5afdc3c337370c", "text": "from llm.llama_index import LlamaClient\nfrom process.process import Process\nfrom typing import Any\n\nclass GenerationProcess(Process):\n    def __init__(self, client: LlamaClient, prompt: str) -> None:\n        super().__init__()\n        self.client = client\n        self.prompt = prompt\n\n\n    def run(self, args: Any = None):\n        index = self.client.load_index()\n        self.client.query(index, self.prompt)", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "5cbd1482-1fa2-4051-ba75-2a2011905ef5": {"__data__": {"id_": "5cbd1482-1fa2-4051-ba75-2a2011905ef5", "embedding": null, "metadata": {"file_name": "keyprocess.py", "relative_path": "build/lib/process/keyprocess.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d9aec004b3a8bdfc84ab04e5004aeafd", "node_type": "4", "metadata": {"file_name": "keyprocess.py", "relative_path": "build/lib/process/keyprocess.py"}, "hash": "35b0dd5bf4ee9283d05756e55eb26c918eddc80d7324d0b36bb4cdb5d835d61d"}}, "hash": "fdc8316fa36067cb58e29a6a17fd5ea9ef64c82a9ab16a98ad8324e356f667eb", "text": "import os\nfrom typing import Any\nfrom process.process import Process\n\n\nclass KeyProcess(Process):\n    def __init__(self, key: str) -> None:\n        super().__init__()\n        self.key = key\n\n    def run(self, args: None):\n        os.environ['OPENAI_API_KEY'] = self.key", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "5395780a-4eda-4c2a-93c5-b15f7d497346": {"__data__": {"id_": "5395780a-4eda-4c2a-93c5-b15f7d497346", "embedding": null, "metadata": {"file_name": "process.py", "relative_path": "build/lib/process/process.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "2a3bd915ffa006d3be173566419d4f03", "node_type": "4", "metadata": {"file_name": "process.py", "relative_path": "build/lib/process/process.py"}, "hash": "c3c106facea6a04e07767e9a53356d3c0ce8e81b72ab1ed0c42779dbabdb40fe"}}, "hash": "5c79e5b261974cc1fc85c73542663b611cb870ad48124e01b7d22bcafdc17957", "text": "from abc import abstractmethod\nfrom typing import Any\n\nclass Process:\n    def __init__(self) -> None:\n        pass\n    \n    @abstractmethod\n    def run(self, args: Any):\n        pass", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "2930dbee-eda8-41a6-b306-47cb6268a929": {"__data__": {"id_": "2930dbee-eda8-41a6-b306-47cb6268a929", "embedding": null, "metadata": {"file_name": "llama_index.py", "relative_path": "llm/llama_index.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "471e918c4c6dd451b62cbafc115bdb9b", "node_type": "4", "metadata": {"file_name": "llama_index.py", "relative_path": "llm/llama_index.py"}, "hash": "d5ba10581230bcceaa11b97ab080c6e23a3c8b00e9ad855c1a153b8a3b4bc4e6"}, "3": {"node_id": "050abbd6-89ca-45ea-b009-e618fdfac1cd", "node_type": "1", "metadata": {"file_name": "llama_index.py", "relative_path": "llm/llama_index.py"}, "hash": "4fdd06502351e09a0d7a4d544ef7151f34ab4d50929776854259b2b223cdd128"}}, "hash": "85a0c0b081e06c0b50d2b31b8cf56b7c71d8924a79c992361262fbc37c7f06e1", "text": "import hashlib\nfrom pydoc import text\nfrom typing import List\nimport llama_index\nfrom llama_index.indices.base import BaseIndex\nfrom llama_index.schema import BaseNode\nfrom llama_index.storage.docstore.simple_docstore import SimpleDocumentStore\nfrom llama_index.storage.index_store.simple_index_store import SimpleIndexStore\nfrom llama_index.vector_stores.simple import SimpleVectorStore\nimport openai\nimport os\nfrom data.errors import NO_API_KEY\nfrom llama_index import Document, ServiceContext, StorageContext, VectorStoreIndex, load_index_from_storage\nfrom util.fs import read_file\nfrom llama_index.node_parser import SimpleNodeParser\nfrom llama_index.llms import OpenAI\nfrom util.fs import get_bootstrap_dir\n\nclass LlamaClient:\n    def __init__(self) -> None:\n        api_key = os.getenv(\"OPENAI_API_KEY\")\n        if api_key is None:\n            print(NO_API_KEY)\n            exit(0)\n        else:\n            openai.api_key = api_key\n\n    def generate_doc(self, filepath: str) -> Document:\n        filename = filepath.split('/')[-1]\n        relative_path = os.path.relpath(filepath, os.getcwd())\n        doc =  Document(\n            text=read_file(filepath),\n            extra_info={\n                \"file_name\": filename,", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "050abbd6-89ca-45ea-b009-e618fdfac1cd": {"__data__": {"id_": "050abbd6-89ca-45ea-b009-e618fdfac1cd", "embedding": null, "metadata": {"file_name": "llama_index.py", "relative_path": "llm/llama_index.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "471e918c4c6dd451b62cbafc115bdb9b", "node_type": "4", "metadata": {"file_name": "llama_index.py", "relative_path": "llm/llama_index.py"}, "hash": "d5ba10581230bcceaa11b97ab080c6e23a3c8b00e9ad855c1a153b8a3b4bc4e6"}, "2": {"node_id": "2930dbee-eda8-41a6-b306-47cb6268a929", "node_type": "1", "metadata": {"file_name": "llama_index.py", "relative_path": "llm/llama_index.py"}, "hash": "85a0c0b081e06c0b50d2b31b8cf56b7c71d8924a79c992361262fbc37c7f06e1"}, "3": {"node_id": "56d05cc8-3166-4322-bcd9-254438180df6", "node_type": "1", "metadata": {"file_name": "llama_index.py", "relative_path": "llm/llama_index.py"}, "hash": "4f502ac3027502a3ada3b725448bc6e02f6a58d5c0dd72673865435c111c803c"}}, "hash": "4fdd06502351e09a0d7a4d544ef7151f34ab4d50929776854259b2b223cdd128", "text": "\"relative_path\": relative_path\n            }\n        )\n        # Set the ID as the MD5 hash of the filepath \n        hash = hashlib.md5(filepath.encode()).hexdigest()\n        doc.id_ = hash\n        return doc\n\n\n    def parse_nodes(self, docs: List[Document]) -> List[BaseNode]:\n        parser = SimpleNodeParser.from_defaults(\n            chunk_size=512,\n            chunk_overlap=20\n        )\n        nodes = parser.get_nodes_from_documents(docs)\n        return nodes\n\n    def generate_index_from_nodes(self, nodes: List[BaseNode]) -> VectorStoreIndex:\n        llm = OpenAI(model='gpt-4', temperature=0.1)\n        service_context = ServiceContext.from_defaults(\n            llm=llm\n        )\n        index = VectorStoreIndex(nodes, service_context=service_context)\n        return index", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "56d05cc8-3166-4322-bcd9-254438180df6": {"__data__": {"id_": "56d05cc8-3166-4322-bcd9-254438180df6", "embedding": null, "metadata": {"file_name": "llama_index.py", "relative_path": "llm/llama_index.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "471e918c4c6dd451b62cbafc115bdb9b", "node_type": "4", "metadata": {"file_name": "llama_index.py", "relative_path": "llm/llama_index.py"}, "hash": "d5ba10581230bcceaa11b97ab080c6e23a3c8b00e9ad855c1a153b8a3b4bc4e6"}, "2": {"node_id": "050abbd6-89ca-45ea-b009-e618fdfac1cd", "node_type": "1", "metadata": {"file_name": "llama_index.py", "relative_path": "llm/llama_index.py"}, "hash": "4fdd06502351e09a0d7a4d544ef7151f34ab4d50929776854259b2b223cdd128"}, "3": {"node_id": "4622e469-5937-4558-b2a2-60640a64c3ae", "node_type": "1", "metadata": {"file_name": "llama_index.py", "relative_path": "llm/llama_index.py"}, "hash": "4fae0fec5f9eb6b0b284b12c422dde7d6b548957cb3de32d44c7fcfea442057e"}}, "hash": "4f502ac3027502a3ada3b725448bc6e02f6a58d5c0dd72673865435c111c803c", "text": "def query(self, index: BaseIndex, prompt: str):\n        qe = index.as_query_engine(streaming=True)\n        response = qe.query(prompt)\n\n        print('\\n')\n\n        response_text = None\n        if hasattr(response, 'response_gen') and response.response_gen is not None:\n            response_txt = \"\"\n            for text in response.response_gen:\n                print(text, end=\"\", flush=True)\n                response_txt += text\n        print(\"\\n\")\n            \n\n    def save_index(self, index: BaseIndex):\n        storagepath = os.path.join(get_bootstrap_dir(), \"storage\")\n        index.storage_context.persist(storagepath)", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "4622e469-5937-4558-b2a2-60640a64c3ae": {"__data__": {"id_": "4622e469-5937-4558-b2a2-60640a64c3ae", "embedding": null, "metadata": {"file_name": "llama_index.py", "relative_path": "llm/llama_index.py"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "471e918c4c6dd451b62cbafc115bdb9b", "node_type": "4", "metadata": {"file_name": "llama_index.py", "relative_path": "llm/llama_index.py"}, "hash": "d5ba10581230bcceaa11b97ab080c6e23a3c8b00e9ad855c1a153b8a3b4bc4e6"}, "2": {"node_id": "56d05cc8-3166-4322-bcd9-254438180df6", "node_type": "1", "metadata": {"file_name": "llama_index.py", "relative_path": "llm/llama_index.py"}, "hash": "4f502ac3027502a3ada3b725448bc6e02f6a58d5c0dd72673865435c111c803c"}}, "hash": "4fae0fec5f9eb6b0b284b12c422dde7d6b548957cb3de32d44c7fcfea442057e", "text": "def load_index(self) -> BaseIndex:\n        storagepath = os.path.join(get_bootstrap_dir(), \"storage\")\n        storage_context = StorageContext.from_defaults(\n            docstore=SimpleDocumentStore.from_persist_dir(persist_dir=storagepath),\n            vector_store=SimpleVectorStore.from_persist_dir(persist_dir=storagepath),\n            index_store=SimpleIndexStore.from_persist_dir(persist_dir=storagepath),\n        )\n        llm = OpenAI(model='gpt-4', temperature=0.1)\n        service_context = ServiceContext.from_defaults(\n            llm=llm\n        )\n        index = load_index_from_storage(storage_context)\n        index._service_context = service_context\n        return index", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}}, "docstore/ref_doc_info": {"8813e60e0d9f7cacf0c414ae4964816f": {"node_ids": ["633945d4-138a-4fe1-ba18-bf6198b981c7"], "metadata": {"file_name": "setup.py", "relative_path": "setup.py"}}, "471e918c4c6dd451b62cbafc115bdb9b": {"node_ids": ["a33a62aa-a46a-434a-9916-2f4fadfe92a8", "96d1e53a-0d1e-4f63-bb66-45e6f393f6ff", "22011b34-a3a2-47ac-9b15-6c5b994fbc96", "bdef5b8e-72ac-4657-a7f4-c895558f24fb", "57b0ab6d-186c-4589-8fd7-832adfe993f8", "7997fc47-e6df-4a7d-aa65-0040a1a48dfb", "07119bb3-dbed-4cb6-b15c-3acdb7ee71de", "2930dbee-eda8-41a6-b306-47cb6268a929", "050abbd6-89ca-45ea-b009-e618fdfac1cd", "56d05cc8-3166-4322-bcd9-254438180df6", "4622e469-5937-4558-b2a2-60640a64c3ae"], "metadata": {"file_name": "llama_index.py", "relative_path": "llm/llama_index.py"}}, "73dd1e6f7ba6481957549a310c957e4b": {"node_ids": ["f0adbea2-cd6c-4094-baa7-e6b17e164024"], "metadata": {"file_name": "walker.py", "relative_path": "util/walker.py"}}, "3146ead6697fe74d44d166aa2eed024a": {"node_ids": ["fccb5c06-9c28-4831-aec9-72e01bb50be2"], "metadata": {"file_name": "parsers.py", "relative_path": "util/parsers.py"}}, "ff1d8cad4c58af36f3624910ac1be3e1": {"node_ids": ["153d5c7e-5145-418f-8469-678b4d236024", "66e1a7a6-cd46-4b31-b27b-cadd01d2eebb"], "metadata": {"file_name": "fs.py", "relative_path": "util/fs.py"}}, "087008845694f9bddd6c94f117110834": {"node_ids": ["2a543b18-863b-4e75-a148-6a359516dbe1"], "metadata": {"file_name": "md_output.py", "relative_path": "util/md_output.py"}}, "dc7e8b0f6c24d21c7a6403f2759ca818": {"node_ids": ["66048890-36c9-4a2c-a304-a2f36ab38764"], "metadata": {"file_name": "hash_test.py", "relative_path": "script/hash_test.py"}}, "09fe6f109687e4e2026fd8cea14c68ce": {"node_ids": ["87bd40fa-f988-4bef-992a-9ba9e92e40ba", "ded49ff3-9cbc-4a78-b0a6-1ff36140a887"], "metadata": {"file_name": "main.py", "relative_path": "script/main.py"}}, "4c3ec91c7b3ea98fe88f3cd0cfa3f849": {"node_ids": ["5cb53ee6-42d0-45a2-93ee-8d6e3d800e34"], "metadata": {"file_name": "config.py", "relative_path": "data/config.py"}}, "cef4d7c2cadba464db48d1265b4a30c7": {"node_ids": ["b4dd3ed0-e984-4807-a4f4-08c0de2239fc"], "metadata": {"file_name": "errors.py", "relative_path": "data/errors.py"}}, "e41e414f13327d3e8cc2eb129c09b9ce": {"node_ids": ["a4279ccc-e92a-4912-b844-57809a918e7b", "5b8314db-8f1d-49de-a44b-f54811a06f33"], "metadata": {"file_name": "snapshot.py", "relative_path": "data/snapshot.py"}}, "1e2d0c2555792e9e45661a316e9d688a": {"node_ids": ["57a64705-389e-4fda-b0f5-3f821b6e657b"], "metadata": {"file_name": "delete.py", "relative_path": "process/delete.py"}}, "02b2f09e831de8625a047296cc5efbe6": {"node_ids": ["311df7ea-1306-4a1c-8efd-a2142e34f60e", "aac377af-cd27-4c7f-baea-491e619675d3", "f03153fa-41ee-4155-95ec-bcc2b798fd8a"], "metadata": {"file_name": "build.py", "relative_path": "process/build.py"}}, "8880c0d89319431dae3c49d763b11383": {"node_ids": ["a5470978-ef62-4b4b-961b-b9f4aea81720"], "metadata": {"file_name": "generation.py", "relative_path": "process/generation.py"}}, "dde91e35690052e786795b16603467b8": {"node_ids": ["6d0bb17f-ce42-48ef-b4bb-174fff167af0"], "metadata": {"file_name": "keyprocess.py", "relative_path": "process/keyprocess.py"}}, "b15009cde98d00318f0ac4aed9c62783": {"node_ids": ["5b76242e-83ec-4ec8-9e60-5f913ff52a7c"], "metadata": {"file_name": "process.py", "relative_path": "process/process.py"}}, "8a52185c9f9a7ab0dce2a5e9fc84dccd": {"node_ids": ["782eceb8-6eac-49a0-a180-3797b9c31a9f", "6abfcf8e-2c1d-4be0-8218-ecc7908ffc05", "ae9dc63e-af06-4d41-a92f-fc4999a9cf3a", "fe86b5e3-1fb6-4d58-a2b2-562be0d10e56"], "metadata": {"file_name": "llama_index.py", "relative_path": "build/lib/llm/llama_index.py"}}, "ed859f1af1f723ade33122ad20d19010": {"node_ids": ["ce16c0f7-71fd-461a-8c38-b24ad0ac7952"], "metadata": {"file_name": "walker.py", "relative_path": "build/lib/util/walker.py"}}, "a0462033740a6cd37a9588291ad89fdd": {"node_ids": ["1472d2e0-17d5-40c0-b385-e39db42b2a90"], "metadata": {"file_name": "parsers.py", "relative_path": "build/lib/util/parsers.py"}}, "af98f0e16176160af49213efb7201ef5": {"node_ids": ["0ea1aa63-b1a3-474b-aedf-643c9501e26b", "fb5765fe-a265-4242-886a-8b3da8f73dbc"], "metadata": {"file_name": "fs.py", "relative_path": "build/lib/util/fs.py"}}, "2639def6322916535b7c11b75b12ee16": {"node_ids": ["62c517be-3c60-4769-a9e9-9cda726c5551"], "metadata": {"file_name": "md_output.py", "relative_path": "build/lib/util/md_output.py"}}, "4e3fb7d231772335068371bbf17ca1f3": {"node_ids": ["f5da64c4-bec1-49e2-9e24-b43edcd53873"], "metadata": {"file_name": "hash_test.py", "relative_path": "build/lib/script/hash_test.py"}}, "24a25fe904c858c2b257d2e6d8165f9b": {"node_ids": ["853bdd10-d43e-4221-ac7f-4f9533d8a078", "a8f0273f-41e3-43cf-b046-eee446deba9b"], "metadata": {"file_name": "main.py", "relative_path": "build/lib/script/main.py"}}, "330fadb6c2d895324f6ff90fd6e346c7": {"node_ids": ["2286ddd8-3e4b-4082-9888-fe97903f2b0c"], "metadata": {"file_name": "config.py", "relative_path": "build/lib/data/config.py"}}, "d11d604739e0ae4e9975fd32ac402e84": {"node_ids": ["61931ba0-ac02-40f2-9770-248a7c6420c1"], "metadata": {"file_name": "errors.py", "relative_path": "build/lib/data/errors.py"}}, "2db495b92e26bf76ddbc90c959af81b1": {"node_ids": ["bd4810dc-4009-4a1b-be84-cea1b18077f4", "7e309e8b-08b0-4db4-af2d-d0c389ddd7f8"], "metadata": {"file_name": "snapshot.py", "relative_path": "build/lib/data/snapshot.py"}}, "090248470d4ea28d7f2d4b5208597712": {"node_ids": ["a63fa65b-881d-4380-8c88-929d555df0a0"], "metadata": {"file_name": "delete.py", "relative_path": "build/lib/process/delete.py"}}, "6fa6f13a00c78b8a406d654d7593b6b7": {"node_ids": ["6355f745-a496-4d28-abef-d65d79c9312c", "d89469d2-4107-4759-abab-45c89e20043a", "60fbbd02-e267-4b78-bb85-520a9718fd3f"], "metadata": {"file_name": "build.py", "relative_path": "build/lib/process/build.py"}}, "21e2f269418ce99fb490453c45e8727a": {"node_ids": ["c9650001-3a2a-4a0e-8a25-d8ca721f2192"], "metadata": {"file_name": "generation.py", "relative_path": "build/lib/process/generation.py"}}, "d9aec004b3a8bdfc84ab04e5004aeafd": {"node_ids": ["5cbd1482-1fa2-4051-ba75-2a2011905ef5"], "metadata": {"file_name": "keyprocess.py", "relative_path": "build/lib/process/keyprocess.py"}}, "2a3bd915ffa006d3be173566419d4f03": {"node_ids": ["5395780a-4eda-4c2a-93c5-b15f7d497346"], "metadata": {"file_name": "process.py", "relative_path": "build/lib/process/process.py"}}}, "docstore/metadata": {"633945d4-138a-4fe1-ba18-bf6198b981c7": {"doc_hash": "91f1d5478f7d90ebca40e5026e6a6b4d97045f86d49afd88fba26b0078aff179", "ref_doc_id": "8813e60e0d9f7cacf0c414ae4964816f"}, "a33a62aa-a46a-434a-9916-2f4fadfe92a8": {"doc_hash": "bdf6ec546c722d66018a334321d9d17b27b842fb93c160b2b59cb0fd7daf689a", "ref_doc_id": "471e918c4c6dd451b62cbafc115bdb9b"}, "96d1e53a-0d1e-4f63-bb66-45e6f393f6ff": {"doc_hash": "4fdd06502351e09a0d7a4d544ef7151f34ab4d50929776854259b2b223cdd128", "ref_doc_id": "471e918c4c6dd451b62cbafc115bdb9b"}, "22011b34-a3a2-47ac-9b15-6c5b994fbc96": {"doc_hash": "29748a2bd149bbcb07d5fd6359d3d96612c0a53ea8971b9bf81564c20950aa33", "ref_doc_id": "471e918c4c6dd451b62cbafc115bdb9b"}, "f0adbea2-cd6c-4094-baa7-e6b17e164024": {"doc_hash": "aa4edeb52c41e6da8b270f8ad5c8aad2a4d475d3fa743cdcc7996a49e228a854", "ref_doc_id": "73dd1e6f7ba6481957549a310c957e4b"}, "fccb5c06-9c28-4831-aec9-72e01bb50be2": {"doc_hash": "b4be07547c57652a37911171476f2da9a98456f1c08e9e6175fd5fd7e0771d31", "ref_doc_id": "3146ead6697fe74d44d166aa2eed024a"}, "153d5c7e-5145-418f-8469-678b4d236024": {"doc_hash": "e727fec06dc9c5632f600b34c8b3eb73463f37e6b3afbd4004d68328d330b2d8", "ref_doc_id": "ff1d8cad4c58af36f3624910ac1be3e1"}, "66e1a7a6-cd46-4b31-b27b-cadd01d2eebb": {"doc_hash": "482970e1c16823a7bd2bde2e2c6c410b4760c1b2dc097574ded8bd6292b53f01", "ref_doc_id": "ff1d8cad4c58af36f3624910ac1be3e1"}, "2a543b18-863b-4e75-a148-6a359516dbe1": {"doc_hash": "d868bb968dcbb2102e2197c5ce8bb781f75794559e2e4e61f8f094f95046f3f0", "ref_doc_id": "087008845694f9bddd6c94f117110834"}, "66048890-36c9-4a2c-a304-a2f36ab38764": {"doc_hash": "2c6211a0fa55e6cf5c96936b5a17e59294e1194797dfa41f6af2b85a6db5f394", "ref_doc_id": "dc7e8b0f6c24d21c7a6403f2759ca818"}, "87bd40fa-f988-4bef-992a-9ba9e92e40ba": {"doc_hash": "bb28c7af03b75878bf95efde90364dc3b0ecc277071f4dcf5dc9884325aa5205", "ref_doc_id": "09fe6f109687e4e2026fd8cea14c68ce"}, "ded49ff3-9cbc-4a78-b0a6-1ff36140a887": {"doc_hash": "9421f36f715cc193edd5e7051058b46c059307aede717665d559da6d0381c186", "ref_doc_id": "09fe6f109687e4e2026fd8cea14c68ce"}, "5cb53ee6-42d0-45a2-93ee-8d6e3d800e34": {"doc_hash": "5cc45aae7d686e8a472606366a476a4c599c3c0c3408afc3ec425ca5f2cb78a3", "ref_doc_id": "4c3ec91c7b3ea98fe88f3cd0cfa3f849"}, "b4dd3ed0-e984-4807-a4f4-08c0de2239fc": {"doc_hash": "831ec779fc4bb8751b0d4dfaf265847c99191d05264df2b621b2eb6b5f23ec17", "ref_doc_id": "cef4d7c2cadba464db48d1265b4a30c7"}, "a4279ccc-e92a-4912-b844-57809a918e7b": {"doc_hash": "e56ed04a1fb3a55a28a5b4872211618b33766226ba4ec0aefe79bc5505850072", "ref_doc_id": "e41e414f13327d3e8cc2eb129c09b9ce"}, "5b8314db-8f1d-49de-a44b-f54811a06f33": {"doc_hash": "e91a4d460c7c6000a2809227f2ee60ce1213144b981b6f8e92b7d3eb716a996d", "ref_doc_id": "e41e414f13327d3e8cc2eb129c09b9ce"}, "57a64705-389e-4fda-b0f5-3f821b6e657b": {"doc_hash": "49e1f903f07c92073a25ffb467f72c5c71a15f77b058b1e0cc0fb01bf132d559", "ref_doc_id": "1e2d0c2555792e9e45661a316e9d688a"}, "311df7ea-1306-4a1c-8efd-a2142e34f60e": {"doc_hash": "494c13980a4437f277d8262443c9359f26f22b37db86991f9a5a67c0f35281b8", "ref_doc_id": "02b2f09e831de8625a047296cc5efbe6"}, "aac377af-cd27-4c7f-baea-491e619675d3": {"doc_hash": "9c4c0cdc15aac2183b69c0a6b13f3710a93d2b811904db178d863c9d6d1e704f", "ref_doc_id": "02b2f09e831de8625a047296cc5efbe6"}, "f03153fa-41ee-4155-95ec-bcc2b798fd8a": {"doc_hash": "1e23d415c78ebafb3ee3ae161ba4784b76ee8620e9c250037dc7d63a43f0b2cb", "ref_doc_id": "02b2f09e831de8625a047296cc5efbe6"}, "a5470978-ef62-4b4b-961b-b9f4aea81720": {"doc_hash": "82e385958ba5246479627c3d9b3161919f07ec05581c8844ab48f0b695dfc54b", "ref_doc_id": "8880c0d89319431dae3c49d763b11383"}, "6d0bb17f-ce42-48ef-b4bb-174fff167af0": {"doc_hash": "ff3d12ca22d829c115d82376b246b896d3fab068870083529ee320b7c66b125b", "ref_doc_id": "dde91e35690052e786795b16603467b8"}, "5b76242e-83ec-4ec8-9e60-5f913ff52a7c": {"doc_hash": "1b4f9971ff38e3e05cbc03dcc68c56bf176a7fd65f96027668a02d76616c91eb", "ref_doc_id": "b15009cde98d00318f0ac4aed9c62783"}, "bdef5b8e-72ac-4657-a7f4-c895558f24fb": {"doc_hash": "bdf6ec546c722d66018a334321d9d17b27b842fb93c160b2b59cb0fd7daf689a", "ref_doc_id": "471e918c4c6dd451b62cbafc115bdb9b"}, "57b0ab6d-186c-4589-8fd7-832adfe993f8": {"doc_hash": "4fdd06502351e09a0d7a4d544ef7151f34ab4d50929776854259b2b223cdd128", "ref_doc_id": "471e918c4c6dd451b62cbafc115bdb9b"}, "7997fc47-e6df-4a7d-aa65-0040a1a48dfb": {"doc_hash": "944c9fb71f28f7042f798bb571fb71ded609370f35c1f26c536026e4f74d59c0", "ref_doc_id": "471e918c4c6dd451b62cbafc115bdb9b"}, "07119bb3-dbed-4cb6-b15c-3acdb7ee71de": {"doc_hash": "4fae0fec5f9eb6b0b284b12c422dde7d6b548957cb3de32d44c7fcfea442057e", "ref_doc_id": "471e918c4c6dd451b62cbafc115bdb9b"}, "782eceb8-6eac-49a0-a180-3797b9c31a9f": {"doc_hash": "46ec5dab0db0c943804b126a5ab606788fbe239b8218fce42dc1530a7ff33f03", "ref_doc_id": "8a52185c9f9a7ab0dce2a5e9fc84dccd"}, "6abfcf8e-2c1d-4be0-8218-ecc7908ffc05": {"doc_hash": "230930439369d4ebd10cd7ec322d4bd14fd7c2fbfaa3cd1f88e8a3b9f9ae4384", "ref_doc_id": "8a52185c9f9a7ab0dce2a5e9fc84dccd"}, "ae9dc63e-af06-4d41-a92f-fc4999a9cf3a": {"doc_hash": "c17073879593ca258fcf493d521fed158e9249ce489254d93c0da84e3a60a652", "ref_doc_id": "8a52185c9f9a7ab0dce2a5e9fc84dccd"}, "fe86b5e3-1fb6-4d58-a2b2-562be0d10e56": {"doc_hash": "a821b285ce72c56b24ed6433de2e9bc653694ab352b27f99797df67e12a38243", "ref_doc_id": "8a52185c9f9a7ab0dce2a5e9fc84dccd"}, "ce16c0f7-71fd-461a-8c38-b24ad0ac7952": {"doc_hash": "fc1336f9b66c7c04c029b24755e014cdf4783bfc2bf209143ff81b7da14b3007", "ref_doc_id": "ed859f1af1f723ade33122ad20d19010"}, "1472d2e0-17d5-40c0-b385-e39db42b2a90": {"doc_hash": "70eaa01bdeef031b94fb39b5b436b91883f370f4b4fdf4c0748012a3cc02b4ad", "ref_doc_id": "a0462033740a6cd37a9588291ad89fdd"}, "0ea1aa63-b1a3-474b-aedf-643c9501e26b": {"doc_hash": "098de338b16b0a60cd70d1f81e22076ae1199a789954dd75f6eaad96ab40029d", "ref_doc_id": "af98f0e16176160af49213efb7201ef5"}, "fb5765fe-a265-4242-886a-8b3da8f73dbc": {"doc_hash": "be041b68179bee19678aba0ff7a9d641adcc3970ceb5b81ae482c6138706b135", "ref_doc_id": "af98f0e16176160af49213efb7201ef5"}, "62c517be-3c60-4769-a9e9-9cda726c5551": {"doc_hash": "9b17e55b5f5e4fa9a057384fdb7ea0db8d3d5b761e521ed07b95e4c5f8b785c8", "ref_doc_id": "2639def6322916535b7c11b75b12ee16"}, "f5da64c4-bec1-49e2-9e24-b43edcd53873": {"doc_hash": "abf6e2b4547e9312737a5744190ce81078f5cfe6675837732b95585818b9b623", "ref_doc_id": "4e3fb7d231772335068371bbf17ca1f3"}, "853bdd10-d43e-4221-ac7f-4f9533d8a078": {"doc_hash": "afdc59d234d61eb23e0b6bd5250bfe6125ef1034a96a3024402ec17797e6d884", "ref_doc_id": "24a25fe904c858c2b257d2e6d8165f9b"}, "a8f0273f-41e3-43cf-b046-eee446deba9b": {"doc_hash": "e77d87e78d20e78ffef3f18079705a04c724b78117b2f995206f7ba110ee3816", "ref_doc_id": "24a25fe904c858c2b257d2e6d8165f9b"}, "2286ddd8-3e4b-4082-9888-fe97903f2b0c": {"doc_hash": "29231319bb01af0335e4316a16a78917895a43c373eb7c55b9f73d44a6cd4b67", "ref_doc_id": "330fadb6c2d895324f6ff90fd6e346c7"}, "61931ba0-ac02-40f2-9770-248a7c6420c1": {"doc_hash": "7ef10f02f0ef4d3ae00e9af03c04e556f132b83a0567795de1fcd252ffc604a3", "ref_doc_id": "d11d604739e0ae4e9975fd32ac402e84"}, "bd4810dc-4009-4a1b-be84-cea1b18077f4": {"doc_hash": "544dad8dc27837f5af6e3afa4d5a37b3b0f37631686edce6df5d324119ed24e5", "ref_doc_id": "2db495b92e26bf76ddbc90c959af81b1"}, "7e309e8b-08b0-4db4-af2d-d0c389ddd7f8": {"doc_hash": "3e9723625316d68b926d711118e923a4076c62296267807962c6f2138a9d6fc5", "ref_doc_id": "2db495b92e26bf76ddbc90c959af81b1"}, "a63fa65b-881d-4380-8c88-929d555df0a0": {"doc_hash": "246792c7870b5f18d3e4db67c2a6c57e84d388222d2fae3ed5af04161ce695c4", "ref_doc_id": "090248470d4ea28d7f2d4b5208597712"}, "6355f745-a496-4d28-abef-d65d79c9312c": {"doc_hash": "73a2865f5be6186e985d303e7fd8e9d0fa9792399366339131d6a97d0e7be4e0", "ref_doc_id": "6fa6f13a00c78b8a406d654d7593b6b7"}, "d89469d2-4107-4759-abab-45c89e20043a": {"doc_hash": "cca461f991d35072ef667d7d9131637f55e51b800f78029d4ea93b640aefba66", "ref_doc_id": "6fa6f13a00c78b8a406d654d7593b6b7"}, "60fbbd02-e267-4b78-bb85-520a9718fd3f": {"doc_hash": "4d6767c133025bc6e32905f019842f993828e5531ce5571670ead457d11b9baf", "ref_doc_id": "6fa6f13a00c78b8a406d654d7593b6b7"}, "c9650001-3a2a-4a0e-8a25-d8ca721f2192": {"doc_hash": "afdc9b4c2e353056f406658b410562e8a9875f57c8703cab2a5afdc3c337370c", "ref_doc_id": "21e2f269418ce99fb490453c45e8727a"}, "5cbd1482-1fa2-4051-ba75-2a2011905ef5": {"doc_hash": "fdc8316fa36067cb58e29a6a17fd5ea9ef64c82a9ab16a98ad8324e356f667eb", "ref_doc_id": "d9aec004b3a8bdfc84ab04e5004aeafd"}, "5395780a-4eda-4c2a-93c5-b15f7d497346": {"doc_hash": "5c79e5b261974cc1fc85c73542663b611cb870ad48124e01b7d22bcafdc17957", "ref_doc_id": "2a3bd915ffa006d3be173566419d4f03"}, "2930dbee-eda8-41a6-b306-47cb6268a929": {"doc_hash": "85a0c0b081e06c0b50d2b31b8cf56b7c71d8924a79c992361262fbc37c7f06e1", "ref_doc_id": "471e918c4c6dd451b62cbafc115bdb9b"}, "050abbd6-89ca-45ea-b009-e618fdfac1cd": {"doc_hash": "4fdd06502351e09a0d7a4d544ef7151f34ab4d50929776854259b2b223cdd128", "ref_doc_id": "471e918c4c6dd451b62cbafc115bdb9b"}, "56d05cc8-3166-4322-bcd9-254438180df6": {"doc_hash": "4f502ac3027502a3ada3b725448bc6e02f6a58d5c0dd72673865435c111c803c", "ref_doc_id": "471e918c4c6dd451b62cbafc115bdb9b"}, "4622e469-5937-4558-b2a2-60640a64c3ae": {"doc_hash": "4fae0fec5f9eb6b0b284b12c422dde7d6b548957cb3de32d44c7fcfea442057e", "ref_doc_id": "471e918c4c6dd451b62cbafc115bdb9b"}}}